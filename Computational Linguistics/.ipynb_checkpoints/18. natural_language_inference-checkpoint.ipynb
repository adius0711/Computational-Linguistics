{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vs-ySE4wuBpY"
   },
   "source": [
    "# What kind of semantic knowledge do we want?\n",
    "\n",
    "Should be able to solve the following tasks:\n",
    "\n",
    "* Textual entailment (whether $X$ follows from $Y$)\n",
    "* To build up knowledge of facts about the world\n",
    "\n",
    "A lot of knowledge already exists in structured datasets like WordNet, which contain a deep hierarchy of words and how they relate to each other. But, many more things are true in the world than are in any of our databases :)\n",
    "\n",
    "So, we must be creative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niSalkA5DGzZ"
   },
   "source": [
    "# Building a classifier to (try to) do Natural Language Inference (NLI) from sentence embeddings\n",
    "\n",
    "Tools you will take home today:\n",
    "\n",
    "* How to interact with a standard natural language inference dataset (SNLI: https://nlp.stanford.edu/projects/snli/)\n",
    "* Get a better sense for what different **types of inferences** or **entailment** there can be\n",
    "* How to get word embeddings from a model from HuggingFace to use in a classifier\n",
    "* How to build a simple linear classifier (logistic regression) in scikit-learn to do inference classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgrUKmkKgd9n"
   },
   "source": [
    "# \"Solving\" entailment with statistics\n",
    "\n",
    "The general insight behind natural language inference datasets is that **entailment** is a relationship that can be **learned** or **approximated**. With sufficiently large data, we should be able to reconstruct a very large proportion of the knowledge ordinary people have about the real world. Then, we just need to build some kind of **model** that can take a representation of a text, and either:\n",
    "\n",
    "1. Enumerate all valid facts that follow from that knowledge, or,\n",
    "2. Verify for a given fact whether it follows from existing knowledge\n",
    "\n",
    "Nowadays, we build **statistical** models of this relationship, seeking to find what regularities predict entailment between two propositions.\n",
    "\n",
    "In formal semantics, we would think about entailment differently -- perhaps by thinking of all valid subsets of a category. For example, if I ask you whether a _Dachsund_ is a kind of dog or not, the answer is \"certainly yes\" because you know something about what a Dachshund is.\n",
    "\n",
    "<center><img src=\"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/07143625/Dachshund-standing-outdoors.jpg\" width=400 /></center>\n",
    "\n",
    "We can even see what WordNet has to say about Dachshunds:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1PjCNDn8rg_",
    "outputId": "1524ea25-a9f4-41ca-b1b8-836c3a82b8ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[Synset('hunting_dog.n.01')]\n",
      "[Synset('dog.n.01')]\n",
      "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
      "[Synset('animal.n.01')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "print(wordnet.synset(\"dachshund.n.01\").hypernyms())\n",
    "print(wordnet.synset(\"hunting_dog.n.01\").hypernyms())\n",
    "print(wordnet.synset(\"dog.n.01\").hypernyms())\n",
    "print(wordnet.synset(\"domestic_animal.n.01\").hypernyms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDPbx_Rl7yXI"
   },
   "source": [
    "# The Stanford Natural Language Inference Dataset\n",
    "\n",
    "SNLI attempts to turn the question of asking whether a dachshund is a dog or not into a machine learning task. The goal of SNLI is to be able to handle all kinds of questions like the **hypernym** relationships above, but also other types of entailment that encode \"common sense\" knowledge about the world. This dataset has become a staple test dataset in natural language understanding research.\n",
    "\n",
    "This is a three-way classification task. The model is going to use the word embeddings to estimate the probability that each `Hypothesis` either is `neutral` with respect to the original `Text`, or whether there is an `entailment` or `contradiction` relation. If the `Hypothesis` is **entailed** by the `Text`, then this means that the `Hypothesis` MUST be true. If the `Hypothesis` **contradicts** the `Text`, then it must _not_ be the case -- that is, the `Hypothesis` MUST be false.\n",
    "\n",
    "There are approximately 550,000 **training** items, and 10,000 **test** items. We use the test items to evaluate the training items -- we don't want our models to just memorize the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxAX7WAqDMQ1"
   },
   "outputs": [],
   "source": [
    "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import json\n",
    "\n",
    "data = ZipFile('./snli_1.0.zip')\n",
    "data = {name: data.read(name) for name in data.namelist()}\n",
    "\n",
    "# break training data down into lines\n",
    "training_file_contents = data['snli_1.0/snli_1.0_train.jsonl'].decode('utf-8')\n",
    "\n",
    "# store as jsons\n",
    "training_jsons = []\n",
    "for x in training_file_contents.split(\"\\n\"):\n",
    "  if x!='':\n",
    "    training_jsons.append(json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLsOWh3vO4Va",
    "outputId": "511c61c3-22e5-4beb-ed8d-1e0ac5970273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: A person on a horse jumps over a broken down airplane.\n",
      "Hypothesis: A person is training his horse for a competition.\n",
      "Text-Hypothesis Relationship: neutral\n"
     ]
    }
   ],
   "source": [
    "#@title Example sentence pairs and label\n",
    "\n",
    "def print_snli(json_line: dict):\n",
    "  text = json_line['sentence1']\n",
    "  hypothesis = json_line['sentence2']\n",
    "  category = json_line['gold_label']\n",
    "  print(f\"Text: {text}\")\n",
    "  print(f\"Hypothesis: {hypothesis}\")\n",
    "  print(f\"Text-Hypothesis Relationship: {category}\")\n",
    "  \n",
    "print_snli(training_jsons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFqPP7QM-nt6",
    "outputId": "2bb87971-f6f7-40b6-f38c-27290d09547c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: A person on a horse jumps over a broken down airplane.\n",
      "Hypothesis: A person is training his horse for a competition.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: A person on a horse jumps over a broken down airplane.\n",
      "Hypothesis: A person is at a diner, ordering an omelette.\n",
      "Text-Hypothesis Relationship: contradiction\n",
      "\n",
      "Text: A person on a horse jumps over a broken down airplane.\n",
      "Hypothesis: A person is outdoors, on a horse.\n",
      "Text-Hypothesis Relationship: entailment\n",
      "\n",
      "Text: Children smiling and waving at camera\n",
      "Hypothesis: They are smiling at their parents\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: Children smiling and waving at camera\n",
      "Hypothesis: There are children present\n",
      "Text-Hypothesis Relationship: entailment\n",
      "\n",
      "Text: Children smiling and waving at camera\n",
      "Hypothesis: The kids are frowning\n",
      "Text-Hypothesis Relationship: contradiction\n",
      "\n",
      "Text: A boy is jumping on skateboard in the middle of a red bridge.\n",
      "Hypothesis: The boy skates down the sidewalk.\n",
      "Text-Hypothesis Relationship: contradiction\n",
      "\n",
      "Text: A boy is jumping on skateboard in the middle of a red bridge.\n",
      "Hypothesis: The boy does a skateboarding trick.\n",
      "Text-Hypothesis Relationship: entailment\n",
      "\n",
      "Text: A boy is jumping on skateboard in the middle of a red bridge.\n",
      "Hypothesis: The boy is wearing safety equipment.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.\n",
      "Hypothesis: An older man drinks his juice as he waits for his daughter to get off work.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.\n",
      "Hypothesis: A boy flips a burger.\n",
      "Text-Hypothesis Relationship: contradiction\n",
      "\n",
      "Text: An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.\n",
      "Hypothesis: An elderly man sits in a small shop.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: Two blond women are hugging one another.\n",
      "Hypothesis: Some women are hugging on vacation.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: Two blond women are hugging one another.\n",
      "Hypothesis: The women are sleeping.\n",
      "Text-Hypothesis Relationship: contradiction\n",
      "\n",
      "Text: Two blond women are hugging one another.\n",
      "Hypothesis: There are women showing affection.\n",
      "Text-Hypothesis Relationship: entailment\n",
      "\n",
      "Text: A few people in a restaurant setting, one of them is drinking orange juice.\n",
      "Hypothesis: The people are eating omelettes.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: A few people in a restaurant setting, one of them is drinking orange juice.\n",
      "Hypothesis: The people are sitting at desks in school.\n",
      "Text-Hypothesis Relationship: contradiction\n",
      "\n",
      "Text: A few people in a restaurant setting, one of them is drinking orange juice.\n",
      "Hypothesis: The diners are at a restaurant.\n",
      "Text-Hypothesis Relationship: entailment\n",
      "\n",
      "Text: An older man is drinking orange juice at a restaurant.\n",
      "Hypothesis: A man is drinking juice.\n",
      "Text-Hypothesis Relationship: entailment\n",
      "\n",
      "Text: An older man is drinking orange juice at a restaurant.\n",
      "Hypothesis: Two women are at a restaurant drinking wine.\n",
      "Text-Hypothesis Relationship: contradiction\n",
      "\n",
      "Text: An older man is drinking orange juice at a restaurant.\n",
      "Hypothesis: A man in a restaurant is waiting for his meal to arrive.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: A man with blond-hair, and a brown shirt drinking out of a public water fountain.\n",
      "Hypothesis: A blond man getting a drink of water from a fountain in the park.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: A man with blond-hair, and a brown shirt drinking out of a public water fountain.\n",
      "Hypothesis: A blond man wearing a brown shirt is reading a book on a bench in the park\n",
      "Text-Hypothesis Relationship: contradiction\n",
      "\n",
      "Text: A man with blond-hair, and a brown shirt drinking out of a public water fountain.\n",
      "Hypothesis: A blond man drinking water from a fountain.\n",
      "Text-Hypothesis Relationship: entailment\n",
      "\n",
      "Text: Two women who just had lunch hugging and saying goodbye.\n",
      "Hypothesis: The friends scowl at each other over a full dinner table.\n",
      "Text-Hypothesis Relationship: contradiction\n",
      "\n",
      "Text: Two women who just had lunch hugging and saying goodbye.\n",
      "Hypothesis: There are two woman in this picture.\n",
      "Text-Hypothesis Relationship: entailment\n",
      "\n",
      "Text: Two women who just had lunch hugging and saying goodbye.\n",
      "Hypothesis: The friends have just met for the first time in 20 years, and have had a great time catching up.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: Two women, holding food carryout containers, hug.\n",
      "Hypothesis: The two sisters saw each other across the crowded diner and shared a hug, both clutching their doggie bags.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: Two women, holding food carryout containers, hug.\n",
      "Hypothesis: Two groups of rival gang members flipped each other off.\n",
      "Text-Hypothesis Relationship: contradiction\n",
      "\n",
      "Text: Two women, holding food carryout containers, hug.\n",
      "Hypothesis: Two women hug each other.\n",
      "Text-Hypothesis Relationship: entailment\n",
      "\n",
      "Text: A Little League team tries to catch a runner sliding into a base in an afternoon game.\n",
      "Hypothesis: A team is trying to score the games winning out.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: A Little League team tries to catch a runner sliding into a base in an afternoon game.\n",
      "Hypothesis: A team is trying to tag a runner out.\n",
      "Text-Hypothesis Relationship: entailment\n",
      "\n",
      "Text: A Little League team tries to catch a runner sliding into a base in an afternoon game.\n",
      "Hypothesis: A team is playing baseball on Saturn.\n",
      "Text-Hypothesis Relationship: contradiction\n",
      "\n",
      "Text: The school is having a special event in order to show the american culture on how other cultures are dealt with in parties.\n",
      "Hypothesis: A school hosts a basketball game.\n",
      "Text-Hypothesis Relationship: contradiction\n",
      "\n",
      "Text: The school is having a special event in order to show the american culture on how other cultures are dealt with in parties.\n",
      "Hypothesis: A high school is hosting an event.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: The school is having a special event in order to show the american culture on how other cultures are dealt with in parties.\n",
      "Hypothesis: A school is hosting an event.\n",
      "Text-Hypothesis Relationship: entailment\n",
      "\n",
      "Text: High fashion ladies wait outside a tram beside a crowd of people in the city.\n",
      "Hypothesis: The women do not care what clothes they wear.\n",
      "Text-Hypothesis Relationship: contradiction\n",
      "\n",
      "Text: High fashion ladies wait outside a tram beside a crowd of people in the city.\n",
      "Hypothesis: Women are waiting by a tram.\n",
      "Text-Hypothesis Relationship: entailment\n",
      "\n",
      "Text: High fashion ladies wait outside a tram beside a crowd of people in the city.\n",
      "Hypothesis: The women enjoy having a good fashion sense.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n",
      "Text: A man, woman, and child enjoying themselves on a beach.\n",
      "Hypothesis: A child with mom and dad, on summer vacation at the beach.\n",
      "Text-Hypothesis Relationship: neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in training_jsons[0:40]:\n",
    "  print_snli(line)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fe0ZSaUx6iEH"
   },
   "source": [
    "## Getting a model ready for our NLI prediction task\n",
    "\n",
    "Goal: Predict one of three labels in SNLI given a preamble (`Text`) and a sentence that is potentially implied by that text (`Hypothesis`).\n",
    "\n",
    "To do this the modern way, we are going to need to extract word or sentence embedding representations from a language model. \n",
    "\n",
    "### Given what you know about the data above, what features do you think are going to matter for our models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQDSVrZ_Hbg8"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3Npif2zGcAF"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel, DistilBertTokenizer \n",
    "\n",
    "model = DistilBertModel.from_pretrained(\n",
    "    'distilbert-base-uncased', output_hidden_states=True)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "608pu38wHaGB"
   },
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence, neural_model, neural_tokenizer,\n",
    "                           cls_token, layer_number):\n",
    "  tokenized = neural_tokenizer(sentence, return_tensors='pt')\n",
    "  embeddings = neural_model(**tokenized)['hidden_states']\n",
    "  layerwise_embeddings = embeddings[layer_number]\n",
    "  if cls_token:\n",
    "    # then grab very first index\n",
    "    out_embedding = layerwise_embeddings[0].detach().numpy().mean(axis=0)\n",
    "  else:\n",
    "    # then average all indices\n",
    "    out_embedding = layerwise_embeddings.detach().numpy().mean(axis=1)\n",
    "  \n",
    "  return out_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jWanX7ooPSMv"
   },
   "outputs": [],
   "source": [
    "def process_snli_distilbert(jsons: list, neural_model, neural_tokenizer,\n",
    "                            cls_token=True, layer_number=-1):\n",
    "  \"\"\"\n",
    "  This function will convert all our jsons into a dataset for sklearn\n",
    "  jsons: list[dict] of SNLI data\n",
    "  neural_model: e.g., DistilBertModel from huggingface\n",
    "  neural_tokenizer: e.g., DistilBertTokenizer from huggingface\n",
    "  cls_token: Which word embedding(s) do you want (defaults to CLS/first)\n",
    "  layer_number: What layer do you want (defaults to last)\n",
    "  \"\"\"\n",
    "  Xs, ys = [], []\n",
    "  for record in jsons:\n",
    "    sent1, sent2 = record['sentence1'], record['sentence2']\n",
    "    label = record['gold_label']\n",
    "    # for the heck of it, concatenate the two\n",
    "    concatenated = sent1 + \" \" + sent2\n",
    "    embedding = get_sentence_embedding(\n",
    "        concatenated, neural_model, neural_tokenizer,\n",
    "        cls_token, layer_number)\n",
    "    Xs.append(embedding)\n",
    "    ys.append(label)\n",
    "  return Xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvvzPgbEmDUy"
   },
   "source": [
    "### What other representations could we try to use to characterize the relationships between two sentences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bZmFy8nf5dy"
   },
   "source": [
    "## Building our classifier\n",
    "\n",
    "We are going to create a standard classifier -- the goal of this model is to find the best way to use the word embeddings to carve up the space of categories. When we build a **linear classifier** we are trying to find **lines** that separate our categories (**classes**). The property of our model that we are aiming for is **linear separability**. In the SNLI context, we have 3 classes (entailment, contradiction, neutral), and up to 768 **slopes** we can learn on our lines. (This is just like $y = mx + b$ in school!)\n",
    "\n",
    "<center><img src=\"https://machinelearningmastery.com/wp-content/uploads/2020/01/Scatter-Plot-of-Multi-Class-Classification-Dataset.png\" width=500 /></center>\n",
    "\n",
    "If we can draw lines that separate the blue blob from the orange and green, and a line that separates the orange from the green, we have a nice lil classifier that knows where to put every new data point. While this plot is in two dimensions, our data are much bigger than that. The math is thankfully still the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "3YyOa4PYe8RT"
   },
   "outputs": [],
   "source": [
    "# downsample because nobody has time to embed 550,000 sentences lol\n",
    "sub_training_jsons = [x for i, x in enumerate(training_jsons) if i%15==0]\n",
    "\n",
    "# now create our training dataset\n",
    "train_X, train_y = process_snli_distilbert(sub_training_jsons, model, tokenizer,\n",
    "                                           cls_token=False, layer_number=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GnK3SFMfq3_"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(np.vstack(train_X), train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I5RH_cHjRSL"
   },
   "source": [
    "## Evaluating our classifier\n",
    "\n",
    "In order to know if our models are any good, we first want to see if our model is learning anything from our training data. To do this, we have to compute some kind of accuracy measure. For this, we will need to think about how to count up incorrect guesses.\n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/1024/1*u8PgZ_84no_swpLnuMf-PQ.png\" width=500 /></center>\n",
    "\n",
    "In our **multiclass** classification task for SNLI, we have three labels. But, let's pretend we only have two for now: **entailment** and **contradiction**. Our models will make guesses about **entailment** and **contradiction** -- so we just need to count up all four of these different combinations.\n",
    "\n",
    "| Gold Label      | Predicted==entailment | Predicted==contradiction|\n",
    "| ----------- | ----------- | -----------|\n",
    "| entailment      | Correct       | Incorrect |\n",
    "| contradiction   | Incorrect        | Correct |\n",
    "\n",
    "\n",
    "When we evaluate our models, we are often using the proportions of correct responses relative to different kinds of errors. This is what the two estimates of $Precision$ and $Recall$ are for.\n",
    "\n",
    "<center>\n",
    "$\\text{Precision} = p(\\text{gold label}==\\text{entailment} | \\text{predicted}==\\text{entailment})$\n",
    "</center>\n",
    "\n",
    "> Pokemon analogy: How many of the Pokemon that you caught were Pikachus?\n",
    "\n",
    "<center>\n",
    "$\\text{Recall} = p(\\text{predicted}==\\text{entailment} | \\text{gold label}==\\text{entailment})$\n",
    "</center>\n",
    "\n",
    "> Pokemon analogy: How many of all of the Pikachus in the world did you catch?\n",
    "\n",
    "<center>\n",
    "And then, if we want to combine these two things together, we compute the F score, which allows us to weigh Precision and Recall. The resulting score is a **harmonic mean**. If we weight them equally, then we compute what is called $F_1$. \n",
    "\n",
    "$F_1 = 2 \\cdot \\large \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlPdNQRVm5qe",
    "outputId": "dc9d869e-6ed5-46b9-c1a6-4f8ac66e9b6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6506529977915315"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Scoring our model on guesses for the training data\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(train_y,\n",
    "         classifier.predict(np.vstack(train_X)),\n",
    "         average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdXiDWWmv0Z_",
    "outputId": "d167ec6f-7a2b-4aaf-cd80-1f6251aa2f4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5005404557061213"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(train_y,\n",
    "         # our predicted training labels\n",
    "         classifier.predict(np.vstack(train_X)),\n",
    "         average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjuQyeviwP34",
    "outputId": "cc365236-22c0-48ee-8511-aa193943cb4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6506529977915315"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "sum(train_y == classifier.predict(np.vstack(train_X))) / len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcSLcXQJw4R0",
    "outputId": "191d4fcf-1457-4493-8e61-43ed6591d1a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'-': 1,\n",
       "         'contradiction': 12178,\n",
       "         'entailment': 13100,\n",
       "         'neutral': 11398})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(classifier.predict(np.vstack(train_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jLJhWJfnJ0-"
   },
   "source": [
    "At least our model isn't just predicting one class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "GRNdjzJSf0Ur"
   },
   "outputs": [],
   "source": [
    "# break test data down into lines\n",
    "test_file_contents = data['snli_1.0/snli_1.0_test.jsonl'].decode('utf-8')\n",
    "\n",
    "# store as jsons\n",
    "test_jsons = []\n",
    "for x in test_file_contents.split(\"\\n\"):\n",
    "  if x!='':\n",
    "    test_jsons.append(json.loads(x))\n",
    "\n",
    "# create our test dataset\n",
    "test_X, test_y = process_snli_distilbert(test_jsons, model, tokenizer, cls_token=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZyr7mJuzhdf",
    "outputId": "63dd9d1f-45d4-4fd1-af30-efad1e44aa27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4707575281996137"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assess performance on our test data\n",
    "f1_score(test_y,\n",
    "         classifier.predict(np.vstack(test_X)),\n",
    "         average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zd_9bnc8nSDx"
   },
   "source": [
    "Yikes! That's not great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cFFsM18wzikH",
    "outputId": "b4513105-b3df-42c3-bbed-a0baa178667f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6236"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_y == classifier.predict(np.vstack(test_X))) / len(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FB_0TiwfE20a"
   },
   "source": [
    "## Preview of Friday!\n",
    "\n",
    "We will be building more classifiers to keep getting practice in this area.\n",
    "\n",
    "Next time will be to learn more about what kinds of entailment we might want to capture. How do we create **propositions** to represent our utterances, so we can learn that two sentences are similar?\n",
    "\n",
    "### Semantic role frameworks\n",
    "\n",
    "### PropBank\n",
    "\n",
    "#### Plain sentence:\n",
    "    But I will never learn that.\n",
    "\n",
    "\n",
    "#### Leaves:\n",
    "\n",
    "    0   But\n",
    "    1   I\n",
    "           coref: IDENT        m_0   1-1    I\n",
    "    2   will\n",
    "    3   never\n",
    "    4   learn\n",
    "           sense: learn-v.1\n",
    "           prop:  learn.01\n",
    "            v          * -> 4:0,  learn\n",
    "            ARGM-DIS   * -> 0:0,  But\n",
    "            ARG0       * -> 1:1,  I\n",
    "            ARGM-MOD   * -> 2:0,  will\n",
    "            ARGM-TMP   * -> 3:1,  never\n",
    "            ARG1       * -> 5:1,  that\n",
    "    5   that\n",
    "           coref: IDENT        284   5-5    that\n",
    "    6   /.\n",
    "\n",
    "\n",
    "### FrameNet\n",
    "\n",
    "https://framenet.icsi.berkeley.edu/fndrupal/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "natural_language_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
