{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic_models_and_senses.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz0Iq1jRP1aq"
      },
      "source": [
        "# From documents back to words\n",
        "\n",
        "This week we have covered:\n",
        "  * `word2vec`\n",
        "  * Document embeddings with Latent Semantic Analysis\n",
        "  * Clustering algorithms\n",
        "\n",
        "Goals of prior analyses:\n",
        "  * Learn the representations of words\n",
        "  * Combine words in different ways to characterize documents\n",
        "  * Create groups and assign labels to them\n",
        "\n",
        "The algorithms we have talked about are neat from a data perspective:\n",
        "  * Have intuitive, geometric interpretations\n",
        "  * Work well in practice for practical natural language processing\n",
        "  * But do not always work with language data perfectly\n",
        "\n",
        "## The skew of language data\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/3e/Dirichlet_distributions.png\" width=450 />\n",
        "\n",
        "e.g., word frequency distributions:\n",
        "\n",
        "<img src=\"https://finnaarupnielsen.files.wordpress.com/2013/10/brownzipf.png\" width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3Ia9o1hP1SV"
      },
      "source": [
        "# Generative Models\n",
        "\n",
        "Before we talk about Latent Dirichlet Allocation (LDA), let's talk a bit about what kinds of models we are learning today. LDA is what is called a **generative** model, which can be used to *create* data from what it learns. It makes the assumption of a **data generating process**. Understanding what this might look like will help us understand what we learn when we build topic models. The vast majority of models that we use in contemporary NLP are **discriminative models** (e.g., `word2vec`, `BERT`, logistic regression, etc.).\n",
        "\n",
        "Intuitively, how do we end up with a document? What steps do we go through?\n",
        "\n",
        "<details>\n",
        "<summary>Step 1: Message formulation\n",
        "</summary>\n",
        "Someone has to have something they want to say (a message)\n",
        "</details>\n",
        "<details>\n",
        "<summary>\n",
        "Step 2: Articulation\n",
        "</summary>\n",
        "Someone has to use their knowledge of language to say it\n",
        "</details>\n",
        "<details>\n",
        "<summary>\n",
        "Step 3: Interpretation\n",
        "</summary>\n",
        "Someone else has to interpret what was said in (2) and try to reconstruct (1)\n",
        "</details>\n",
        "\n",
        "One way these three steps have beeen thought of is as a **noisy channel model** proposed by Claude Shannon. This model is essentially just the same as Bayes' theorem (aka Bayes rule).\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/d/d4/Thomas_Bayes.gif\" />\n",
        "\n",
        "The Reverend Bayes\n",
        "\n",
        "## Bayes Theorem\n",
        "\n",
        "We discussed Bayes Theorem briefly a few weeks ago when we talked about conditional probabilities. A conditional probability is like looking at a **subset** of the data. For example:\n",
        "\n",
        "$p(\\text{Word} = w_i | \\text{Context} = c_j)$ refers to the probability of a word $w_i$ given a context $c_j$. \n",
        "\n",
        "That is, among all the contexts where we have seen $c_j$, what proportion of events did we also see $w_i$?\n",
        "\n",
        "If we think about *bigrams* -- two word sequences -- again, Bayes Theorem allows us to shift between different kinds of probabilities:\n",
        "\n",
        "$p(\\text{Word} = w_i | \\text{Context} = c_j) \\approx \\large \\frac{p(\\text{Context} = c_j | w_i ) p(\\text{Word} = w_i)}{p(\\text{Context}=c_j)} $\n",
        "\n",
        "## How does Bayes relate to topic models?\n",
        "\n",
        "When estimating language models, we have spent a **lot** of time trying to find $p(w | c)$ by looking at **term frequencies** in TF-IDF, or by computing counts of words in bag-of-words representations. But, if we want to know what kinds of topics are present in a document, we actually need to **invert the question**.\n",
        "\n",
        "That is, we need to use the information about the words to define documents, rather than defining words by the documents they occur in. \n",
        "\n",
        "In order to do this, we flip the formula -- we are trying to best approximate the *topics* of our documents using the words that we have in our vocabulary.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_tVVEJ0P1HA"
      },
      "source": [
        "#### Set up for code examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYhp50Bpww_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d0bcd7-e599-460b-e64e-950b1c843dde"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from google.colab import drive, files\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "stopwords_ = set(stopwords.words())\n",
        "with open(\"/content/gdrive/MyDrive/Fall 2021 Computational Linguistics Notebooks/files/abstracts.tsv\") as file:\n",
        "  abstracts = file.readlines()\n",
        "rice = pd.read_excel(\"/content/gdrive/MyDrive/Fall 2021 Computational Linguistics Notebooks/files/Riceetal_SupplementaryMaterials_R1.xlsx\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHbTviSQP1E8"
      },
      "source": [
        "## Latent Dirichlet Allocation (LDA)\n",
        "\n",
        "Using LDA requires making some assumptions:\n",
        "\n",
        "* Documents are composed of multiple parts (e.g., words) --> Prior\n",
        "* Words may be used in different ways in different contexts --> Prior\n",
        "* Words can disambiguate each other\n",
        "* Documents can be composed of multiple topics --> Prior\n",
        "* Terms do not have to be used equally often across topics --> Prior\n",
        "\n",
        "A topic model learns several types of probabilities:\n",
        "\n",
        "* The probabilities of words (out of all tokens)\n",
        "* The probabilities of a word $w_i$ occurring in a topic $k$ (all $k$ topics for $w$ must sum to 1)\n",
        "* The probabilities of a topic $k$ occurring in a document $d$ (all topics $t$ must sum to 1)\n",
        "\n",
        "These components in the `gensim` implementation are referred to as the:\n",
        "\n",
        "* **Term Topic Matrix** --> Strongest terms in each topic (e.g., \"radical\")\n",
        "* **Document Topic Matrix** --> Strongest topics for a given document (e.g., 30% chemistry, 50% math)\n",
        "* **Topic Term Matrix** --> Strongest topics for a given term (e.g., 30% chemistry, 50% math)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm9CgzdU1Gjd"
      },
      "source": [
        "from gensim.models import LdaModel\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "tokenized_abstracts = [word_tokenize(x) for x in abstracts]\n",
        "tokenized_abstracts = [[x for x in y if x not in stopwords_] for y in tokenized_abstracts]\n",
        "\n",
        "bib_dictionary = Dictionary(tokenized_abstracts)\n",
        "bib_corpus = [bib_dictionary.doc2bow(text) for text in tokenized_abstracts]\n",
        "\n",
        "model = LdaModel(corpus=bib_corpus, num_topics=40)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZwt0Kz55Kc4"
      },
      "source": [
        "### Let's explore the components of our trained LDA model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZBuOMQi5Ncp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe01871-82e9-42a1-b9cd-74bd250d759e"
      },
      "source": [
        "# document\n",
        "model.get_term_topics(bib_dictionary.token2id['parsing'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(13, 0.058627035)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1pjO-GYCThy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af66a04e-3d8c-4405-c10b-0f7e1b4ab039"
      },
      "source": [
        "model.get_topic_terms(13)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3933, 0.05852286),\n",
              " (3, 0.054765403),\n",
              " (4307, 0.035495874),\n",
              " (2742, 0.033214096),\n",
              " (2, 0.033086985),\n",
              " (634, 0.028297313),\n",
              " (1851, 0.014612291),\n",
              " (1219, 0.014602867),\n",
              " (2753, 0.014518901),\n",
              " (1, 0.014266459)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMaPORmwCU2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "742885a1-7b28-41c6-b19e-83bbd8f13ce8"
      },
      "source": [
        "for term, score in model.get_topic_terms(13):\n",
        "  print(bib_dictionary[term])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parsing\n",
            ".\n",
            "parser\n",
            "dependency\n",
            ",\n",
            "syntactic\n",
            "semantic\n",
            "tree\n",
            "trees\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P49q7oRK1o__"
      },
      "source": [
        "### Exploring the topics that LDA learns over our abstracts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUfw9Xt1BuUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27507143-e008-4f76-8279-19404dd5e5e7"
      },
      "source": [
        "model.get_term_topics([bib_dictionary.token2id['dependency']])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(13, array([0.0332691], dtype=float32))]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSQqrle-ER7T"
      },
      "source": [
        "What is the strongest document on the same topic that is most associated with \"parsing\"? I.e., what document is in the same general area?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dna29ns-D-m0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "39c9b737-c404-4817-e650-22f49b7cce54"
      },
      "source": [
        "parsing_affinity = 0\n",
        "top_doc = abstracts[0]\n",
        "for i, doc in enumerate(bib_corpus):\n",
        "  # get topics FOR a document\n",
        "  topics_scores = model.get_document_topics(doc)\n",
        "  for topic, score in topics_scores:\n",
        "    if topic==13 and score > parsing_affinity:\n",
        "      parsing_affinity = score\n",
        "      top_doc = abstracts[i]\n",
        "\n",
        "top_doc"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The de-facto standard decoding method for semantic parsing in recent years has been to autoregressively decode the abstract syntax tree of the target program using a top-down depth-first traversal. In this work, we propose an alternative approach: a Semi-autoregressive Bottom-up Parser (SmBoP) that constructs at decoding step t the top-K sub-trees of height {\\\\mbox{$\\\\leq$}} t. Our parser enjoys several benefits compared to top-down autoregressive parsing. From an efficiency perspective, bottom-up parsing allows to decode all sub-trees of a certain height in parallel, leading to logarithmic runtime complexity rather than linear. From a modeling perspective, a bottom-up parser learns representations for meaningful semantic sub-programs at each step, rather than for semantically-vacuous partial trees. We apply SmBoP on Spider, a challenging zero-shot semantic parsing benchmark, and show that SmBoP leads to a 2.2x speed-up in decoding time and a {\\\\textasciitilde}5x speed-up in training time, compared to a semantic parser that uses autoregressive decoding. SmBoP obtains 71.1 denotation accuracy on Spider, establishing a new state-of-the-art, and 69.5 exact match, comparable to the 69.6 exact match of the autoregressive RAT-SQL+GraPPa.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKljLj48JMkM"
      },
      "source": [
        "# Caveat emptor! A note about topic models as clustering algorithms\n",
        "\n",
        "Unlike PCA, the topics that LDA learns do not have fixed labels. Like K-Means, LDA creates \"latent\" categories that correspond to the different topics. For that reason, on one jump of your notebook, what is in Category 3 will be very different from Category 3 the next time. Or, if you change dimensionality to add more topics, your numbers will change as well. So, always keep an eye out for what topic you are trying to refer to!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MZspE9vHhZV"
      },
      "source": [
        "## Topic models allow us to handle ambiguous words\n",
        "\n",
        "Previously, we have talked about how Latent Semantic Analysis (LSA), and word2vec all leave us with a representation of words that is *completely insensitive to context*.\n",
        "\n",
        "How I interpret the word \"particle\" will change depending on what I am reading:\n",
        "\n",
        "* Chemistry: A unit of matter\n",
        "* Linguistics: A type of morpheme or small word\n",
        "* Meteorology: Small bits of matter suspended in the air\n",
        "\n",
        "Topic models allow us to see contextual predictions -- how much do we think an article is about chemistry? If we think it is about chemistry, does that change how we understand the meaning of the word \"particle\"?\n",
        "\n",
        "Topic models allow us to look at exactly that! What do you think are the most ambiguous words in NLP?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4JhtfhUHxq0"
      },
      "source": [
        "We are going to look for the words that have the most even probability distributions. For this, we need to go back to our code that lets us look at the \"term topics\", or topics associated with a given word.\n",
        "\n",
        "`model.get_term_topics([bib_dictionary.token2id['dependency']])`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EaRw9VNDzfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d39adc06-9296-47e6-c4a4-f937c06a7a3b"
      },
      "source": [
        "n_nonzero = 0\n",
        "for term in bib_dictionary.token2id:\n",
        "  topics = model.get_term_topics(bib_dictionary.token2id[term])\n",
        "  if len(topics) > 0:\n",
        "    n_nonzero += 1\n",
        "\n",
        "n_nonzero"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "164"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNXWB9kXIABn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b6430e-fdbb-4bc2-a532-b049ee5f2846"
      },
      "source": [
        "for term in bib_dictionary.token2id:\n",
        "  topics = model.get_term_topics(bib_dictionary.token2id[term])\n",
        "  if len(topics) > 1:\n",
        "    print(term, len(topics))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "( 9\n",
            ") 10\n",
            ", 38\n",
            ". 38\n",
            "data 3\n",
            "language 4\n",
            "model 2\n",
            "paper 4\n",
            "We 10\n",
            "The 7\n",
            "models 2\n",
            "' 2\n",
            "machine 2\n",
            "systems 2\n",
            "{ 4\n",
            "} 4\n",
            "system 6\n",
            "resources 2\n",
            "using 2\n",
            "method 2\n",
            "task 2\n",
            "translation 2\n",
            "\\ 2\n",
            "semantic 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20truCtvJBUM"
      },
      "source": [
        "The way we would allow words to be *more* ambiguous (assigned to more topics) is by setting different kinds of expectations (or priors) that help the model make decisions.\n",
        "\n",
        "It is also clear that word frequency plays a role. We might need to be clever to handle rare words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMxiO2y4mjOT"
      },
      "source": [
        "# What resources can we use to learn about word meanings?\n",
        "\n",
        "Lots and lots of labeled databases -- but the most well-known one is WordNet. WordNet is a huge resource that tries to group every string into all of its distinct meanings. \n",
        "\n",
        "Like any other resource _Wordnet is **incomplete**_. But, it can be useful for distinguishing between **unrelated** senses of the same string. How it handles **related** senses is another matter.\n",
        "\n",
        "Here is an example of a string with lots of **related** senses:\n",
        "\n",
        "* \"Paper\" can refer to\n",
        "  * _a journal article_ (\"I loved their paper on this topic\")\n",
        "  * physical sheets of paper (\"give me a piece of paper\")\n",
        "  * the material (\"paper was strewn everywhere after the party last week\")\n",
        "\n",
        "(instance of polysemy)\n",
        "\n",
        "Here is an example of a string with lots of **unrelated** senses:\n",
        "\n",
        "* \"Bow\" can refer to\n",
        "  * The side of a ship\n",
        "  * One part of a \"bow and arrow\"\n",
        "  * A ribbon used to wrap packages or hair\n",
        "\n",
        "(instance of homonymy)\n",
        "\n",
        "Understanding what senses get used when is a huge challenge in NLP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uGB0u9NmwWG",
        "outputId": "df011cd8-2710-473d-ebfe-f04bdb1195d8"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3e-hkoom08W",
        "outputId": "93a2cd1b-4631-495c-8b41-4582f5061f14"
      },
      "source": [
        "for sense in wordnet.synsets(\"slick\"):\n",
        "  print(sense)\n",
        "  print(sense.definition())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('slickness.n.03')\n",
            "a slippery smoothness\n",
            "Synset('slick.n.02')\n",
            "a magazine printed on good quality paper\n",
            "Synset('slick.n.03')\n",
            "a film of oil or garbage floating on top of water\n",
            "Synset('slick.n.04')\n",
            "a trowel used to make a surface slick\n",
            "Synset('slick.v.01')\n",
            "make slick or smooth\n",
            "Synset('slick.v.02')\n",
            "give a smooth and glossy appearance\n",
            "Synset('slick.s.01')\n",
            "made slick by e.g. ice or grease\n",
            "Synset('glib.s.02')\n",
            "having only superficial plausibility\n",
            "Synset('satiny.s.01')\n",
            "having a smooth, gleaming surface reflecting light\n",
            "Synset('crafty.s.01')\n",
            "marked by skill in deception\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFot_8ZLiIMY"
      },
      "source": [
        "## Topic models learn how ambiguous words are"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di2Y1fjmJpE5"
      },
      "source": [
        "If there's enough time, we're going to do a feasibility exercise to look at what happens with ambiguous words. For this, we'll load in the Rice et al. (2018) dataset from HW4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhN9m1g4Jyc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8d1c5288-2d79-42ca-ec3d-7f22ffa2480c"
      },
      "source": [
        "# preview ambiguous word data\n",
        "# check out the top of this dataset, only two columns to avoid clutter\n",
        "rice[['line', 'probe']].head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>line</th>\n",
              "      <th>probe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Come on , pack it up !</td>\n",
              "      <td>pack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>We are gon na pack them to the doors .</td>\n",
              "      <td>pack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Everybody pack up whatever you can .</td>\n",
              "      <td>pack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You go home and you pack your bags now ! How '...</td>\n",
              "      <td>pack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I thought I brought an extra pack of gum .</td>\n",
              "      <td>pack</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                line probe\n",
              "0                             Come on , pack it up !  pack\n",
              "1             We are gon na pack them to the doors .  pack\n",
              "2               Everybody pack up whatever you can .  pack\n",
              "3  You go home and you pack your bags now ! How '...  pack\n",
              "4         I thought I brought an extra pack of gum .  pack"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTx0jQdlKuYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "617549c7-c3e3-41cd-f062-355d3930bd1b"
      },
      "source": [
        "# figure out the columns of this dataset\n",
        "rice.columns"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['probe', 'line', 'Rater_1', 'Rater_2', 'Meaning_R1', 'Meaning_R2',\n",
              "       'Meaning_R1_BestGuess', 'Meaning_R2_BestGuess', 'Comment_R1',\n",
              "       'Comment_R2', 'CertainAgreement_R1_R2',\n",
              "       'CertainOrUncertainAgreement_R1_R2'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbcg4fyQKqmC"
      },
      "source": [
        "# subset my data to just where raters agreed\n",
        "agree = rice.loc[rice['CertainAgreement_R1_R2']==1]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-9u22zTKl5g"
      },
      "source": [
        "from gensim.models import LdaModel\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "rice_tokenized = [word_tokenize(x) for x in agree['line'].str.lower()]\n",
        "rice_dictionary = Dictionary(rice_tokenized)\n",
        "rice_corpus = [rice_dictionary.doc2bow(text) for text in rice_tokenized]\n",
        "\n",
        "ambig_lda = LdaModel(corpus=rice_corpus, num_topics=10, minimum_probability=0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz3eAwWzM4rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a5849e-8305-4bd9-b89d-733fcec7ff8f"
      },
      "source": [
        "# find all the unique probes in rice['probes']\n",
        "for term in rice['probe'].unique():\n",
        "  if term in rice_dictionary.token2id.keys():\n",
        "    topics = ambig_lda.get_term_topics(rice_dictionary.token2id[term])\n",
        "    print(term, topics)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pack [(0, 6.7012843e-07), (2, 6.8161394e-06), (4, 3.6192665e-05), (6, 0.00015470246), (7, 4.8771573e-05), (8, 1.2598084e-06)]\n",
            "boxing [(7, 1.8465785e-08)]\n",
            "spear [(4, 2.9770662e-08), (6, 1.5583635e-05), (7, 4.10562e-05)]\n",
            "perk [(2, 2.7570266e-07), (6, 5.292729e-06)]\n",
            "slam [(2, 1.0458667e-05), (6, 1.6346848e-06)]\n",
            "cope [(6, 3.6947224e-08)]\n",
            "mortar [(1, 4.850477e-07), (4, 3.311726e-08), (8, 1.4038118e-06)]\n",
            "sheet [(0, 4.780449e-05), (2, 2.2386962e-06), (4, 6.3887717e-07), (5, 8.604184e-07), (6, 3.4664379e-06), (7, 1.0249078e-08)]\n",
            "race [(0, 0.0002241557), (2, 1.1982501e-06), (3, 5.482213e-05), (4, 3.494444e-05), (5, 0.00029129133), (6, 1.1077971e-05), (7, 1.1939469e-05), (8, 3.7490088e-07), (9, 9.746949e-08)]\n",
            "multiply [(0, 2.9043154e-05), (6, 5.119869e-08), (7, 3.4080514e-08)]\n",
            "banker [(0, 3.6221564e-07), (2, 1.0115738e-05), (3, 5.7532486e-07), (6, 1.9558292e-06), (8, 1.7188546e-08)]\n",
            "stalk [(1, 3.9752535e-08), (6, 2.6054582e-05)]\n",
            "scale [(0, 1.3604407e-06), (1, 5.3925755e-06), (3, 4.711465e-08), (4, 2.2381468e-05), (6, 1.1034849e-06), (7, 1.7550082e-07), (8, 8.712302e-07)]\n",
            "mush [(0, 9.862197e-07)]\n",
            "chip [(0, 1.7686287e-06), (1, 5.105481e-06), (2, 0.00017322566), (4, 1.2427835e-06), (5, 6.682773e-06), (6, 4.656069e-06), (7, 5.823337e-07), (8, 2.5306318e-07), (9, 8.745972e-06)]\n",
            "sage [(0, 2.5604704e-08), (6, 2.9119257e-05)]\n",
            "retainer [(1, 4.3448363e-08), (2, 5.9544845e-07), (6, 8.1286885e-08), (8, 1.08768674e-07)]\n",
            "sash []\n",
            "twit []\n",
            "policy [(0, 5.185386e-06), (2, 7.9743394e-08), (3, 0.00027997105), (5, 2.1284849e-07), (6, 1.1878649e-07), (7, 5.7605092e-08), (8, 1.3987876e-07)]\n",
            "key [(0, 5.42625e-05), (1, 1.4646327e-05), (2, 0.00021603273), (3, 3.7937727e-07), (4, 1.751477e-05), (6, 7.915948e-05), (7, 0.00016567612), (8, 6.389463e-06)]\n",
            "stem [(0, 1.7976133e-06), (2, 1.1462014e-08), (4, 1.1957341e-08), (6, 1.5149633e-05), (7, 6.3681846e-06)]\n",
            "peep [(6, 1.5535588e-07)]\n",
            "mite []\n",
            "toll [(0, 9.473719e-08), (3, 1.0194149e-06), (5, 1.9166032e-08), (6, 1.0621878e-05)]\n",
            "fore [(9, 0.00016641594)]\n",
            "root [(2, 3.5666449e-06), (6, 3.0858955e-05)]\n",
            "strut [(1, 1.4275567e-08), (4, 2.3442793e-08), (9, 2.7858649e-05)]\n",
            "plot [(1, 5.7186575e-08), (2, 1.3894058e-08), (3, 1.5283524e-08), (7, 1.1090973e-07), (9, 6.446542e-05)]\n",
            "skate [(1, 1.1791021e-07), (2, 1.6557706e-08), (3, 1.8629366e-06), (4, 6.2206177e-06), (5, 1.9329998e-07), (7, 1.1596926e-08), (8, 7.2455286e-08), (9, 5.9850234e-05)]\n",
            "chute [(1, 2.2984018e-08), (4, 2.748179e-08), (5, 2.6957078e-08), (9, 4.7222504e-05)]\n",
            "ham [(1, 1.0737684e-08), (3, 2.7270888e-08), (4, 2.637137e-08), (5, 6.8517956e-08), (8, 4.745052e-07), (9, 0.00031470158)]\n",
            "flat [(0, 1.6644037e-06), (1, 0.0002339277), (3, 0.00010156885), (4, 1.1005271e-07), (5, 2.8495344e-07), (6, 5.4166867e-06), (7, 7.682643e-05), (8, 0.00012551257), (9, 0.0009604298)]\n",
            "shook [(2, 5.4174825e-06), (4, 3.2621085e-06), (5, 3.2453862e-08), (6, 1.2847894e-08), (7, 7.0550165e-08), (8, 5.9816676e-07), (9, 0.00018363105)]\n",
            "shag [(1, 3.2620868e-08), (4, 1.1787731e-08), (8, 1.6793442e-07), (9, 8.3150735e-05)]\n",
            "funk [(1, 1.1612936e-07), (7, 1.2506209e-08), (9, 7.4353804e-05)]\n",
            "box [(0, 8.452241e-06), (4, 7.655005e-05), (5, 0.00018776176), (6, 0.00024191818), (7, 7.584576e-05), (8, 1.0343427e-05)]\n",
            "gage [(3, 1.5939099e-08), (9, 1.1646346e-06)]\n",
            "ash [(1, 1.6781986e-08), (5, 5.044013e-08), (7, 3.0430243e-08), (9, 7.922065e-05)]\n",
            "thinner [(1, 1.32858e-08), (9, 7.209154e-05)]\n",
            "cuff [(1, 1.953257e-08), (9, 2.0965334e-05)]\n",
            "chase [(1, 3.4122143e-06), (3, 1.8798929e-06), (4, 1.2644365e-08), (5, 2.6627333e-07), (8, 8.053947e-08), (9, 0.00022355368)]\n",
            "lighten [(5, 2.149168e-07), (8, 1.14067715e-08), (9, 0.00014640414)]\n",
            "compact [(7, 3.0853923e-07), (9, 0.00016291336)]\n",
            "spill [(1, 4.7854957e-08), (5, 4.079316e-06), (7, 3.1885328e-08), (8, 9.0029424e-08), (9, 2.8029313e-05)]\n",
            "buck [(0, 6.524112e-05), (1, 0.000104036895), (4, 1.6110991e-05), (5, 3.8546992e-07), (6, 1.7330602e-07), (7, 3.744382e-05), (8, 5.2167765e-05), (9, 0.00024673407)]\n",
            "jog [(1, 1.558984e-08), (5, 1.06817595e-07), (8, 1.634886e-08), (9, 0.0001100195)]\n",
            "clock [(6, 0.00014651909)]\n",
            "plump [(9, 7.7422555e-07)]\n",
            "burden [(0, 2.2000406e-06), (6, 1.7571712e-06), (8, 1.0808561e-05)]\n",
            "tow [(0, 2.5106543e-08), (1, 1.3024389e-07), (2, 4.193918e-08), (3, 1.5464406e-06), (4, 3.1920198e-08), (5, 1.3448135e-07), (6, 1.0526747e-08), (7, 1.6462849e-07), (8, 3.915714e-08)]\n",
            "corporal [(0, 0.00010617245), (6, 0.0005394888)]\n",
            "match [(0, 0.00046426256), (2, 1.85268e-06), (5, 5.8811464e-05), (6, 4.949563e-06)]\n",
            "tier [(0, 3.471407e-08), (3, 4.5480445e-07), (5, 1.1021103e-08), (6, 1.229221e-08), (7, 7.102082e-08)]\n",
            "pound [(0, 0.00048204913), (7, 3.166637e-05)]\n",
            "freak [(6, 0.00018799111)]\n",
            "chord [(0, 1.132898e-07), (1, 6.28297e-08), (2, 6.3308704e-08), (3, 2.221835e-05), (5, 6.2161575e-08), (7, 3.8383586e-08), (8, 3.0159935e-08), (9, 1.2213521e-08)]\n",
            "nag [(4, 1.4394903e-06), (8, 3.7836986e-07), (9, 1.1725009e-05)]\n",
            "scrub [(5, 3.9995602e-06), (9, 0.00025446623)]\n",
            "limb [(0, 5.1324554e-07), (1, 1.659071e-08), (2, 4.0558416e-07), (3, 1.1013823e-06), (4, 1.7259481e-07), (5, 7.095772e-08), (6, 1.6341877e-08), (7, 1.4240901e-05), (8, 9.1643483e-07)]\n",
            "entrance [(0, 3.256765e-06), (1, 1.6716025e-07), (2, 2.8779212e-07), (3, 1.6812471e-06), (4, 6.232743e-08), (5, 4.9362832e-08), (6, 5.1607503e-07), (7, 0.00012406698), (8, 7.898832e-08), (9, 2.4024553e-08)]\n",
            "bridge [(0, 9.010566e-05), (3, 0.00022527673), (6, 1.7698141e-05), (8, 6.6830858e-06)]\n",
            "piano [(0, 7.37714e-08), (2, 1.9146466e-06), (6, 4.3791307e-08), (8, 0.00011205237)]\n",
            "tend [(7, 0.00024592195)]\n",
            "post [(8, 8.158609e-05)]\n",
            "cost [(8, 0.00021116967)]\n",
            "bully [(0, 7.7991774e-07), (1, 2.3581332e-07), (2, 6.2413176e-07), (3, 3.8031928e-06), (4, 8.487742e-06), (5, 5.1642782e-08), (6, 1.717557e-08), (7, 6.559888e-08), (8, 3.8486146e-08)]\n",
            "pat [(6, 3.192408e-05), (8, 6.430724e-07)]\n",
            "woof [(1, 1.8852125e-08), (3, 8.3623576e-07), (5, 9.847606e-06)]\n",
            "maroon [(2, 1.6135846e-08), (3, 1.15793535e-08), (5, 2.1300005e-08)]\n",
            "chum [(0, 1.2133022e-08), (1, 7.873431e-07), (2, 2.6013081e-08), (3, 6.9799285e-08), (4, 1.4625097e-07), (5, 1.1199835e-07), (6, 2.3885379e-08), (7, 3.4832528e-08), (8, 4.83456e-08)]\n",
            "net [(0, 1.919809e-07), (1, 6.596113e-07), (2, 3.12515e-06), (3, 0.00035673662), (4, 1.6415424e-07), (5, 5.3756696e-07), (6, 1.0667951e-06), (7, 5.1575944e-06), (8, 3.1646476e-05), (9, 1.2969777e-07)]\n",
            "crash [(0, 0.00016888563), (1, 0.0001678626), (2, 2.196243e-05), (3, 1.8613782e-05), (4, 1.1288408e-05), (5, 1.5865919e-05), (6, 1.8491893e-07), (7, 0.000101725884), (8, 2.9344339e-05)]\n",
            "camp [(0, 0.00035040732), (3, 1.9953749e-08), (4, 1.4192175e-05), (6, 1.228332e-07)]\n",
            "truck [(3, 0.0010666798)]\n",
            "wit [(6, 9.619377e-06), (8, 1.2842401e-05)]\n",
            "staff [(0, 0.000111373396), (1, 1.1755541e-05), (2, 1.7161006e-05), (3, 6.305173e-06), (4, 8.289795e-06), (5, 1.4376958e-06), (6, 1.8596696e-05), (7, 5.0420582e-05), (8, 9.2632007e-07), (9, 1.67622e-06)]\n",
            "rib [(8, 1.5817257e-05), (9, 5.800059e-05)]\n",
            "pit [(3, 0.00014970201), (4, 2.4267343e-05)]\n",
            "sap [(0, 7.237038e-07), (1, 5.3023e-07), (7, 5.3120707e-06), (8, 1.3889661e-06)]\n",
            "gloss [(0, 1.155031e-07), (1, 9.523014e-08), (2, 1.8626976e-07), (3, 1.3595918e-07), (4, 1.5697309e-07), (5, 1.8319932e-06), (6, 3.696471e-08), (7, 1.1758338e-08), (9, 2.842964e-08)]\n",
            "temple [(4, 8.551503e-05), (6, 5.1360225e-06)]\n",
            "rut [(0, 1.3228203e-06), (1, 1.804519e-07), (2, 7.195138e-08), (3, 1.09394726e-07), (4, 1.6750846e-07), (5, 4.8351735e-06), (6, 1.8014164e-08), (7, 1.4538287e-08), (8, 5.7001967e-07), (9, 1.9596419e-08)]\n",
            "trap [(0, 4.5096162e-06), (1, 6.8074695e-07), (2, 1.4127376e-06), (3, 4.912654e-07), (4, 5.059857e-05), (5, 2.267719e-05), (6, 8.180838e-05), (7, 3.516612e-07), (8, 6.0708555e-07), (9, 4.6872646e-08)]\n",
            "rye [(1, 1.7769968e-07), (9, 0.00023253245)]\n",
            "stripe [(2, 2.1019557e-06), (6, 2.9444484e-08), (7, 5.658467e-06)]\n",
            "prayer [(0, 6.0891116e-06), (1, 7.421577e-06), (2, 7.740414e-06), (3, 2.413734e-06), (4, 2.8518466e-06), (5, 1.5189332e-05), (6, 6.706323e-05), (7, 7.2610105e-06), (8, 3.7213827e-06), (9, 2.4570882e-08)]\n",
            "rash [(0, 4.9382093e-06), (1, 1.4634131e-06), (2, 9.457141e-07), (3, 6.473618e-05), (4, 9.695048e-07), (5, 2.2349877e-07), (6, 4.771462e-07), (7, 1.702796e-07), (8, 1.6923879e-07), (9, 3.8494036e-06)]\n",
            "toil [(0, 2.8687933e-05), (1, 1.0939118e-07), (4, 5.838501e-07), (5, 2.5515112e-07), (7, 2.525758e-06), (9, 1.09721485e-08)]\n",
            "batter [(0, 1.35896835e-05), (1, 1.242585e-05), (2, 1.3783188e-06), (3, 1.3937032e-06), (4, 1.9766678e-06), (5, 0.00031715046), (6, 1.9018615e-05), (7, 2.287146e-06), (8, 7.862566e-07), (9, 3.726998e-06)]\n",
            "fleet [(0, 0.000105807856), (2, 4.812195e-08), (3, 2.0796476e-08)]\n",
            "rifle [(1, 8.846215e-06), (3, 0.00031175537), (9, 1.47130495e-05)]\n",
            "beetle [(0, 7.524363e-08), (1, 1.6036752e-07), (2, 2.6154535e-07), (3, 9.449275e-06), (4, 2.6828138e-07), (5, 1.6657177e-07), (6, 1.0431253e-07), (7, 3.9605885e-07), (8, 1.258119e-08), (9, 3.4206806e-07)]\n",
            "skipper [(5, 5.0820545e-05), (7, 2.652121e-06), (9, 1.7670987e-05)]\n",
            "nip [(0, 2.1530082e-05), (1, 4.798447e-08), (2, 3.4378897e-07), (3, 5.0289692e-08), (4, 1.3812782e-08), (5, 1.5743643e-06), (6, 5.4600246e-06), (7, 2.0247997e-08), (8, 6.051425e-06), (9, 2.266077e-08)]\n",
            "tract [(0, 1.9830183e-07), (1, 1.4720585e-07), (2, 5.7542064e-08), (3, 1.27474805e-05), (5, 4.7505762e-07), (6, 5.3533203e-08), (7, 1.0672144e-06), (9, 3.6057564e-08)]\n",
            "sperm [(0, 1.565989e-06), (1, 8.580626e-05), (2, 2.2801775e-07), (3, 1.3050245e-06), (4, 9.34248e-07), (5, 3.843447e-06), (6, 1.0705679e-08), (7, 1.0223683e-05), (8, 4.2576093e-07), (9, 5.42649e-06)]\n",
            "flag [(9, 0.0011090091)]\n",
            "sock [(0, 4.8170677e-06), (1, 1.9070885e-05), (2, 5.720207e-06), (3, 9.749517e-06), (4, 6.9131414e-07), (5, 7.2331056e-07), (6, 3.6092072e-06), (7, 3.7078996e-06), (8, 1.2955308e-06), (9, 2.057454e-05)]\n",
            "impress [(1, 0.00021874212), (4, 1.7122302e-06), (8, 1.2298495e-08), (9, 2.0601929e-05)]\n",
            "quail [(0, 1.5180336e-07), (1, 9.101551e-07), (2, 5.551977e-06), (3, 2.24471e-08), (4, 5.396694e-07), (5, 6.368069e-06), (6, 8.376921e-08), (7, 1.4401478e-08), (8, 5.644761e-08), (9, 5.324058e-07)]\n",
            "alley [(9, 0.000609319)]\n",
            "tanner [(1, 5.417663e-06)]\n",
            "reel [(0, 1.2012157e-06), (1, 1.7012615e-06), (2, 8.3783146e-07), (3, 5.000755e-07), (4, 1.6504152e-06), (5, 5.5022447e-06), (6, 4.16272e-07), (7, 3.4337185e-07), (8, 5.054966e-07), (9, 5.5467297e-07)]\n",
            "rip [(2, 5.625563e-05), (4, 9.98417e-07), (6, 1.9082549e-05)]\n",
            "jig [(0, 1.7807043e-08), (1, 1.7344536e-06), (2, 3.3294311e-06), (3, 2.4277398e-08), (4, 1.8449194e-07), (5, 1.0649978e-06), (6, 1.3011454e-07), (8, 1.7842181e-06), (9, 8.100829e-08)]\n",
            "waffle [(0, 5.185151e-07), (1, 9.764092e-07), (2, 5.1334445e-07), (3, 1.7366879e-06), (4, 8.7549015e-06), (5, 3.5765376e-07), (6, 2.8569247e-07), (7, 1.4441446e-06), (8, 5.042308e-07), (9, 2.4670217e-05)]\n",
            "tee [(0, 5.4961085e-08), (1, 1.3490171e-06), (2, 4.1159416e-07), (3, 2.218855e-06), (4, 4.6440205e-06), (5, 4.1950963e-07), (6, 9.20594e-07), (7, 2.9785073e-07), (8, 7.0739284e-06), (9, 1.15280585e-07)]\n",
            "hip [(0, 3.7656837e-06), (1, 1.5792831e-06), (2, 1.7166399e-06), (3, 5.00148e-05), (4, 6.744044e-06), (5, 0.00015170692), (6, 1.6558188e-05), (7, 8.279486e-06), (8, 7.5803273e-06), (9, 8.654161e-07)]\n",
            "rocky [(4, 2.186566e-06), (8, 2.3943758e-05)]\n",
            "slick [(3, 4.517052e-05), (7, 9.48455e-06)]\n",
            "stole [(3, 0.0006682331)]\n",
            "refund [(0, 6.394376e-08), (1, 1.0370491e-05), (2, 3.6907786e-06), (3, 1.5593588e-06), (4, 5.3101684e-07), (5, 1.0940637e-06), (6, 1.2937504e-06), (7, 3.3520582e-06), (8, 2.279344e-06), (9, 2.5671432e-06)]\n",
            "bore [(0, 2.1390952e-05), (1, 1.9488092e-05), (2, 2.2916086e-06), (3, 1.8576044e-07), (4, 1.4263115e-06), (5, 7.924123e-08), (6, 5.313066e-07), (7, 5.9804615e-06), (8, 6.2627765e-07), (9, 3.0602285e-05)]\n",
            "founder [(1, 1.9919848e-06), (7, 2.5571775e-05), (9, 1.995804e-05)]\n",
            "cab [(0, 4.2697633e-05), (2, 2.0577332e-08), (3, 1.771746e-05), (5, 4.70336e-05), (7, 1.6981532e-05), (8, 3.36964e-05)]\n",
            "cosmetic [(0, 1.837323e-06), (1, 9.341986e-06), (2, 1.8190263e-05), (3, 3.010466e-07), (4, 1.5195053e-07), (5, 0.00010295514), (6, 8.76789e-07), (7, 1.5078241e-07), (8, 2.1863939e-07), (9, 1.9690403e-06)]\n",
            "pie [(0, 0.00019156148), (2, 2.6669977e-07), (6, 3.679408e-05)]\n",
            "slug [(0, 5.28349e-06), (1, 1.38230425e-05), (2, 2.0280715e-06), (3, 7.214408e-07), (4, 1.1057087e-06), (5, 8.674703e-07), (6, 4.6493935e-07), (7, 1.2478367e-06), (8, 1.5704848e-06), (9, 1.1487326e-06)]\n",
            "raven [(0, 4.1789565e-07), (1, 3.4753523e-06), (2, 9.3923103e-07), (3, 7.3112624e-06), (4, 4.7306523e-07), (5, 2.7029094e-07), (6, 9.598729e-08), (7, 1.7206565e-05), (8, 3.0878263e-07), (9, 4.931486e-07)]\n",
            "blow [(0, 2.6548463e-08), (3, 0.000722813), (4, 0.00020710503), (6, 9.1367504e-08)]\n",
            "bark [(6, 3.5146273e-05)]\n",
            "lead [(0, 0.0001042917), (2, 0.00016272423), (8, 7.836135e-05)]\n",
            "trace [(4, 5.750737e-05), (6, 7.0083006e-05)]\n",
            "raft [(0, 8.115668e-06), (3, 2.608837e-05), (9, 7.9993726e-05)]\n",
            "yard [(4, 0.0003230364), (6, 2.222473e-05)]\n",
            "pump [(9, 0.00029890263)]\n",
            "mid [(0, 1.9447507e-05), (1, 2.0855872e-07), (2, 6.9705595e-07), (3, 1.743714e-05), (4, 2.7962454e-07), (5, 1.381792e-06), (6, 1.0646953e-06), (7, 1.814645e-06), (9, 4.6324003e-06)]\n",
            "hooker [(2, 3.5259076e-05), (8, 1.9685162e-08)]\n",
            "shark [(0, 5.468261e-07), (6, 9.985475e-05)]\n",
            "launch [(1, 0.0008424679), (2, 8.278835e-05), (3, 9.4179544e-05)]\n",
            "beaver [(0, 4.6001242e-07), (1, 6.8352706e-06), (2, 1.5751316e-06), (3, 1.8115551e-06), (4, 1.6215182e-06), (5, 3.8420778e-05), (6, 9.649247e-06), (7, 1.0482727e-06), (8, 7.268357e-07), (9, 4.02778e-07)]\n",
            "heel [(0, 2.3039522e-06), (6, 8.3075435e-07), (8, 2.7941906e-05)]\n",
            "gob [(1, 3.387293e-05), (3, 0.000106781095)]\n",
            "jet [(0, 3.708874e-05), (7, 4.7646736e-05), (8, 1.8786772e-05)]\n",
            "costly [(6, 2.2729067e-05)]\n",
            "slew [(3, 2.1923163e-06), (5, 7.585346e-08), (7, 3.623373e-05), (8, 1.5881533e-08)]\n",
            "halt [(9, 0.00011719001)]\n",
            "gang [(3, 2.1878162e-05), (9, 0.00078083505)]\n",
            "counter [(7, 0.000114164475), (8, 3.0101073e-05)]\n",
            "pike [(0, 2.0357036e-05), (2, 7.885424e-07), (9, 1.7109919e-07)]\n",
            "arch [(3, 1.1764644e-06), (6, 4.3706717e-05)]\n",
            "former [(4, 3.475742e-05)]\n",
            "sewer [(0, 7.5189196e-06), (1, 3.861939e-06), (2, 1.2051796e-05), (3, 2.3721755e-06), (4, 1.1649585e-05), (5, 5.4576294e-06), (6, 7.149482e-06), (7, 1.7193934e-05), (8, 2.4583142e-06), (9, 5.624095e-06)]\n",
            "sin [(0, 6.280091e-07), (5, 0.00024980848)]\n",
            "fold [(4, 2.8878887e-06), (6, 9.621707e-06), (8, 0.00011339267)]\n",
            "peaked [(0, 1.4688767e-05), (1, 1.1989582e-05), (8, 8.571757e-06)]\n",
            "bent [(0, 7.184658e-05), (2, 0.0005750057), (6, 2.5242902e-05)]\n",
            "cosmic [(1, 1.4613141e-06), (4, 4.554264e-05)]\n",
            "swallow [(7, 0.00018737967)]\n",
            "vet [(0, 7.4940533e-07), (1, 9.233765e-06), (2, 2.7408344e-06), (3, 6.5299096e-06), (4, 1.5789246e-06), (5, 3.7830225e-06), (6, 2.0384166e-06), (7, 5.1979123e-06), (8, 4.2101e-06), (9, 3.0055335e-06)]\n",
            "peer [(0, 1.9607896e-06), (1, 1.749563e-06), (2, 1.0231333e-06), (3, 5.5924e-06), (4, 5.302545e-06), (5, 1.7366035e-06), (6, 5.9233653e-06), (7, 3.1181214e-06), (8, 2.7696075e-07), (9, 8.672462e-07)]\n",
            "boring [(4, 6.3068e-05), (5, 1.6558961e-07), (8, 9.3016515e-06)]\n",
            "cue [(9, 0.00020654307)]\n",
            "sheer [(0, 7.502224e-06), (1, 9.144187e-06), (2, 3.8430876e-06), (3, 3.486721e-05), (4, 9.30832e-07), (5, 3.3797082e-06), (6, 6.612246e-06), (7, 8.435186e-06), (8, 1.9202218e-06), (9, 6.1576748e-06)]\n",
            "list [(0, 0.00024293475), (9, 0.00067558436)]\n",
            "ring [(0, 2.2957406e-06), (2, 0.00014410082), (3, 9.522389e-06), (6, 4.3366217e-05), (7, 0.00017407439), (8, 9.949885e-05)]\n",
            "cat [(0, 3.4046553e-07), (4, 6.772864e-07), (9, 0.0024794296)]\n",
            "pro [(9, 0.00036040062)]\n",
            "forge [(0, 2.7416265e-06), (1, 4.6946775e-06), (2, 2.1867618e-06), (3, 3.6831768e-06), (4, 6.8047495e-07), (5, 1.3995835e-06), (6, 1.3540645e-06), (7, 2.621918e-06), (8, 4.4998515e-06), (9, 8.316747e-07)]\n",
            "rocket [(0, 1.0100479e-05), (5, 0.0004703641)]\n",
            "stern [(0, 7.995857e-05)]\n",
            "painter [(0, 7.650156e-06), (1, 4.580082e-06), (2, 2.7754484e-05), (3, 7.442726e-06), (4, 3.915475e-06), (5, 4.088453e-06), (6, 4.2670586e-06), (7, 3.3436195e-06), (8, 3.560677e-06), (9, 4.019348e-06)]\n",
            "rank [(3, 0.00019980599)]\n",
            "host [(0, 0.00018256642)]\n",
            "imperial [(0, 8.606926e-05), (3, 0.00017243747), (4, 1.8387374e-06), (9, 3.4478286e-05)]\n",
            "meter [(0, 5.6274757e-06), (1, 5.796661e-06), (2, 8.145489e-06), (3, 7.658996e-06), (4, 2.4018852e-06), (5, 1.0594168e-05), (6, 2.175743e-06), (7, 1.2129217e-06), (8, 3.0028978e-06), (9, 8.952317e-06)]\n",
            "slip [(4, 9.521775e-05)]\n",
            "junk [(4, 0.00017676422)]\n",
            "dock [(0, 2.1152933e-05), (1, 6.9425264e-06), (2, 3.297711e-06), (3, 3.6632777e-05), (4, 3.7512816e-06), (5, 2.4974499e-05), (6, 5.6957874e-06), (7, 1.5125482e-05), (8, 1.4021963e-05), (9, 3.600564e-06)]\n",
            "corruption [(1, 0.00016616538), (9, 0.00019584276)]\n",
            "poop [(0, 1.1459398e-05), (7, 7.157494e-07), (9, 0.00032431312)]\n",
            "test [(0, 0.00025943268), (2, 2.8448032e-06), (7, 0.00018155416), (8, 0.00020451304)]\n",
            "tag [(3, 0.0003021717), (6, 2.8954862e-06)]\n",
            "dug [(0, 6.640314e-05), (1, 1.541147e-05), (3, 0.00025180617), (8, 1.1469396e-06)]\n",
            "rap [(2, 3.7512118e-07), (4, 0.000115867784), (7, 1.2807152e-05)]\n",
            "pose [(9, 0.00034435713)]\n",
            "hawk [(6, 0.00014226262)]\n",
            "log [(0, 0.00027214407)]\n",
            "league [(0, 0.0003838077)]\n",
            "brook [(3, 5.566002e-05), (5, 3.08423e-05), (8, 1.660521e-06)]\n",
            "pulse [(3, 0.0010964771)]\n",
            "mark [(6, 3.752071e-05), (7, 0.0005851289), (8, 3.6972306e-05)]\n",
            "shed [(7, 0.00017315282)]\n",
            "tender [(2, 0.00068781216)]\n",
            "span [(0, 2.6349993e-05), (2, 4.715455e-05)]\n",
            "drove [(4, 8.948814e-05), (5, 2.2709619e-08), (6, 3.2066117e-05)]\n",
            "mule [(1, 0.00068401033), (4, 3.1614472e-05), (6, 9.908732e-07)]\n",
            "council [(9, 0.00075226714)]\n",
            "strapping [(0, 6.473448e-06), (1, 6.068872e-08), (2, 5.184377e-06), (3, 5.84776e-06), (4, 3.290818e-06), (5, 9.541292e-07), (6, 6.345707e-07), (7, 6.1470196e-08), (8, 9.408241e-07)]\n",
            "fell [(0, 8.528848e-06), (4, 2.5730611e-05), (6, 0.00040646837), (7, 4.6754543e-05)]\n",
            "corn [(0, 6.4734576e-07), (6, 0.00020562192)]\n",
            "pawn [(0, 8.166109e-06), (1, 2.629913e-05), (2, 6.739968e-06), (3, 6.0434604e-06), (4, 9.743289e-06), (5, 6.0048962e-05), (6, 2.4806166e-06), (7, 1.9744739e-05), (8, 1.3889365e-05), (9, 1.0843115e-05)]\n",
            "peel [(0, 0.00025590477), (6, 2.5223988e-05)]\n",
            "buggy [(0, 3.180769e-05), (7, 0.00014778024)]\n",
            "sow [(0, 8.02059e-06), (1, 4.3627783e-06), (2, 8.459249e-06), (3, 7.238205e-07), (4, 1.113091e-05), (5, 1.6818221e-05), (6, 1.5069237e-06), (7, 4.324288e-06), (8, 2.6377563e-06), (9, 1.446059e-06)]\n",
            "pile [(4, 1.2173217e-08), (9, 0.00058885297)]\n",
            "rare [(2, 1.4280764e-05), (4, 2.295076e-05), (5, 8.898714e-05), (7, 5.003128e-06), (9, 0.0005101059)]\n",
            "smack [(0, 4.0084946e-05), (1, 0.00012551148), (4, 2.9631914e-05), (6, 2.2334216e-05), (7, 3.1405098e-06), (8, 1.2622469e-05), (9, 3.1029256e-07)]\n",
            "utter [(0, 1.9882073e-05), (1, 2.7206584e-05), (2, 2.066679e-05), (3, 1.7961594e-05), (4, 5.5582914e-06), (5, 2.5622307e-05), (6, 1.0148195e-05), (7, 2.9482519e-05), (8, 1.3662011e-05), (9, 1.944835e-06)]\n",
            "fluke [(0, 1.0814973e-05), (1, 0.00013120867), (2, 2.2735745e-05), (4, 1.10008834e-07), (7, 8.194459e-06)]\n",
            "whale [(1, 0.00071619364)]\n",
            "cape [(2, 8.493255e-08), (4, 5.888734e-07), (6, 1.766641e-08), (8, 0.00011162286), (9, 1.5300326e-06)]\n",
            "stall [(1, 0.00042500946), (3, 6.96561e-05), (4, 1.4600347e-05)]\n",
            "ringer [(0, 4.4251706e-07), (5, 3.605796e-05), (9, 0.00023144417)]\n",
            "lighter [(6, 7.353593e-05)]\n",
            "van [(8, 0.00016323001)]\n",
            "fret [(1, 0.00027920314), (2, 1.127883e-05)]\n",
            "refrain [(0, 9.413792e-06), (1, 3.0191348e-05), (2, 8.483623e-06), (3, 2.9015997e-05), (4, 6.2622416e-06), (5, 8.647598e-06), (6, 4.851835e-06), (7, 1.3589502e-05), (8, 2.8350044e-06), (9, 2.511008e-05)]\n",
            "prune [(3, 0.0001858185), (4, 3.2155704e-06)]\n",
            "hail [(7, 0.00019365473)]\n",
            "rock [(0, 0.00019468226), (1, 0.0017925977), (2, 3.270653e-08), (6, 9.779199e-07)]\n",
            "reef [(4, 0.00010284837)]\n",
            "fly [(6, 0.0010189614)]\n",
            "fry [(5, 0.00059008325), (7, 2.204141e-05), (8, 1.5115928e-06)]\n",
            "limp [(0, 4.9486985e-08), (1, 4.6759713e-05), (2, 8.6578474e-08), (3, 2.2725187e-07), (4, 0.000114623435), (5, 3.269387e-08), (6, 3.0110275e-08), (9, 1.1340086e-08)]\n",
            "row [(3, 0.000835142)]\n",
            "rate [(6, 0.00035753258)]\n",
            "tot [(0, 2.0719153e-06), (1, 2.5665642e-07), (2, 1.4985098e-06), (3, 1.19183994e-07), (4, 6.512207e-07), (5, 3.0428225e-07), (6, 8.2598e-08), (7, 3.941295e-08), (8, 4.8771574e-07), (9, 9.949079e-07)]\n",
            "knot [(0, 0.00021533172), (1, 1.870631e-08), (8, 1.1935944e-08)]\n",
            "sounding [(0, 5.7643978e-05), (1, 2.0960359e-05), (2, 1.2329139e-05), (3, 1.5366326e-05), (4, 2.098686e-05), (5, 2.5679205e-05), (6, 7.866583e-06), (7, 1.088104e-05), (8, 1.3702331e-05), (9, 4.9444137e-05)]\n",
            "rail [(9, 0.00069494057)]\n",
            "rag [(9, 0.00052150403)]\n",
            "pop [(2, 5.7022087e-05), (5, 5.9741145e-05), (6, 0.00038608385), (9, 0.00040856664)]\n",
            "lime [(3, 0.00037684682), (6, 1.7346678e-05)]\n",
            "gee [(0, 1.895568e-08), (6, 1.5847007e-08), (9, 0.0013269689)]\n",
            "dotty [(0, 2.3272898e-06), (1, 3.4225246e-07), (2, 1.703946e-07), (3, 6.1178945e-08), (4, 2.0517061e-06), (5, 1.1336833e-06), (6, 1.15306094e-07), (7, 7.842717e-08), (8, 1.226633e-08), (9, 3.2455583e-07)]\n",
            "fudge [(2, 1.7377333e-08), (4, 3.5408063e-06), (5, 0.00011533717), (9, 0.00042314344)]\n",
            "fit [(5, 0.00024319832), (7, 0.00046678333), (9, 1.595943e-07)]\n",
            "rook [(1, 1.2945334e-07), (5, 0.00015850305), (7, 1.6089571e-07)]\n",
            "gore [(0, 8.706122e-07), (1, 6.076477e-06), (2, 1.7405861e-06), (3, 1.8346756e-06), (4, 5.8931613e-07), (5, 1.1073397e-05), (6, 2.8257068e-07), (7, 1.9217443e-06), (8, 2.9737093e-06), (9, 9.30005e-07)]\n",
            "shower [(0, 0.00055221585)]\n",
            "nap [(0, 9.232611e-06), (1, 2.9441608e-05), (2, 3.071151e-05), (3, 2.5730611e-05), (4, 1.914602e-05), (5, 1.8377077e-05), (6, 1.1224e-05), (7, 7.623914e-06), (8, 6.281697e-05), (9, 1.944788e-05)]\n",
            "stable [(0, 9.22956e-05), (4, 1.2191859e-05), (6, 5.8224654e-05), (7, 2.4147597e-05), (9, 1.6967886e-05)]\n",
            "pink [(0, 0.00053663197), (2, 3.2602518e-08), (6, 1.0470158e-06)]\n",
            "console [(6, 0.00016363057)]\n",
            "bud [(0, 0.00029336577), (6, 4.4289154e-05)]\n",
            "bang [(0, 1.9871077e-05), (5, 0.00075120036)]\n",
            "diet [(4, 0.00015493235)]\n",
            "riddle [(0, 2.884601e-05), (1, 0.00046768633), (2, 3.7409518e-05), (7, 9.668978e-06)]\n",
            "card [(3, 0.0016216313)]\n",
            "jag [(5, 1.0106182e-05), (6, 9.463917e-07), (8, 7.4431387e-06), (9, 1.7377266e-08)]\n",
            "sole [(0, 0.0002494345), (1, 0.0002679088), (4, 2.105326e-08)]\n",
            "zip [(6, 0.00022977446)]\n",
            "port [(8, 7.8596725e-07), (9, 0.0010997162)]\n",
            "ray [(8, 0.00037115935)]\n",
            "clutch [(0, 2.2975485e-07), (1, 3.2548215e-08), (2, 0.000129696), (3, 1.9059982e-08), (5, 2.1577893e-07), (6, 2.881495e-08), (7, 0.0001040254), (8, 5.249675e-05), (9, 1.3735863e-07)]\n",
            "spike [(3, 0.00079844234)]\n",
            "kitty [(0, 1.6367934e-05), (9, 0.002082073)]\n",
            "gum [(0, 0.0005561312), (4, 7.349421e-07)]\n",
            "gin [(0, 1.4230698e-06), (7, 0.00030328755), (9, 1.133366e-05)]\n",
            "firm [(1, 0.0015491691)]\n",
            "base [(6, 0.00020819892), (9, 0.00058666966)]\n",
            "ear [(0, 0.0015960687)]\n",
            "spray [(6, 0.0002567273), (9, 2.1817854e-08)]\n",
            "chuck [(1, 0.00081106933), (9, 2.88604e-07)]\n",
            "strain [(0, 2.8818295e-05), (9, 0.00087650516)]\n",
            "mast [(0, 1.4032904e-07), (1, 6.2970666e-06), (2, 5.5216833e-06), (3, 0.0003161663)]\n",
            "bust [(8, 0.00024041724)]\n",
            "shore [(5, 0.0009300676), (9, 1.7665005e-07)]\n",
            "cop [(8, 0.00010243059), (9, 0.0008349354)]\n",
            "invalid [(0, 1.8847984e-05), (1, 3.883499e-05), (2, 2.4777357e-05), (3, 4.8952097e-05), (4, 1.2248732e-05), (5, 3.1403284e-05), (6, 1.624316e-05), (7, 1.545228e-05), (8, 8.374461e-06), (9, 2.2186503e-05)]\n",
            "angle [(1, 1.2107427e-07), (2, 6.951846e-05), (4, 0.0002652119), (6, 1.0083394e-07)]\n",
            "spruce [(0, 1.8753028e-05), (1, 4.8815084e-05), (2, 3.5202196e-05), (3, 6.728003e-06), (4, 2.56892e-05), (5, 1.4894576e-05), (6, 1.3411583e-05), (7, 6.139813e-06), (8, 2.2499684e-05), (9, 8.51297e-06)]\n",
            "pine [(4, 0.0003248545)]\n",
            "barrow [(1, 5.278786e-06), (7, 1.7075121e-05)]\n",
            "band [(4, 1.0449693e-07), (9, 0.0034162328)]\n",
            "tacky [(3, 7.922949e-05), (5, 0.0007324131), (6, 1.2103789e-07)]\n",
            "intimate [(0, 8.0832695e-05), (1, 5.033545e-05), (2, 5.2058327e-05), (3, 3.8916925e-05), (4, 4.2307543e-05), (5, 5.5023054e-05), (6, 3.12058e-05), (7, 4.1779804e-05), (8, 1.6320735e-05), (9, 3.135095e-05)]\n",
            "pry [(0, 2.4709492e-05), (1, 2.7579472e-05), (2, 2.0948746e-05), (3, 3.0567866e-05), (4, 3.081058e-05), (5, 2.0895812e-05), (6, 2.5301879e-05), (7, 1.8740639e-05), (8, 6.0303882e-05), (9, 7.4926497e-06)]\n",
            "lap [(0, 0.0007282721)]\n",
            "grave [(0, 0.0007137165)]\n",
            "earnest [(0, 5.6814624e-05), (1, 3.0701296e-05), (2, 3.0410474e-05), (3, 5.1280913e-05), (4, 2.3954033e-05), (5, 1.9321447e-05), (6, 8.450574e-06), (7, 2.5242685e-05), (8, 1.05139e-05), (9, 1.1746599e-05)]\n",
            "lumber [(0, 0.00045688442)]\n",
            "seal [(6, 3.034552e-07), (7, 0.0006478007), (8, 2.2130864e-05)]\n",
            "cortex [(7, 0.00018400216)]\n",
            "mate [(2, 0.0004905489), (6, 1.1319067e-05)]\n",
            "hack [(0, 9.717061e-07), (2, 0.00027269928)]\n",
            "stove [(2, 4.1196076e-06), (7, 0.0007169193)]\n",
            "pace [(3, 0.00018867361), (4, 4.723868e-05), (6, 0.00015936594)]\n",
            "rating [(2, 0.00027559372), (8, 2.5158797e-06), (9, 1.33966905e-05)]\n",
            "dam [(5, 0.0009953554)]\n",
            "chow [(0, 1.6826243e-05), (1, 5.4988326e-05), (2, 3.797168e-05), (3, 3.7244914e-05), (4, 4.083483e-05), (5, 8.621984e-05), (6, 2.6377698e-05), (7, 1.7469996e-05), (8, 2.6370757e-05), (9, 9.155623e-05)]\n",
            "fair [(4, 0.0001300357), (6, 0.00036998463)]\n",
            "bus [(6, 0.00065654056)]\n",
            "dab [(3, 0.00021861636), (4, 3.295537e-05), (5, 3.1908374e-05)]\n",
            "hobby [(5, 1.9112588e-06), (6, 8.372242e-06), (7, 0.00041425135), (9, 0.00037954465)]\n",
            "haze [(0, 2.8307912e-05), (1, 3.687526e-05), (2, 5.9195704e-06), (3, 8.103306e-05), (4, 1.708338e-05), (5, 4.085816e-05), (6, 9.667946e-06), (7, 3.4213597e-05), (8, 9.278174e-06), (9, 4.7331258e-05)]\n",
            "chump [(0, 3.0120947e-05), (1, 5.334604e-05), (2, 6.4311105e-05), (3, 7.61992e-05), (4, 7.240139e-05), (5, 0.00014646139), (6, 3.0071149e-05), (7, 1.3180631e-05), (8, 2.9263601e-05), (9, 4.7074755e-05)]\n",
            "duck [(5, 0.0022560062)]\n",
            "repair [(0, 3.8666614e-05), (3, 0.00067172904), (7, 0.00010768656)]\n",
            "cashier [(0, 3.5231347e-05), (1, 0.00014026811), (2, 3.7114605e-05), (3, 4.021064e-05), (4, 2.85221e-05), (5, 2.5449644e-05), (6, 3.3850032e-05), (7, 2.962612e-05), (8, 2.7787431e-05), (9, 2.9206198e-05)]\n",
            "nun [(3, 0.0011608984)]\n",
            "chess [(1, 3.5349845e-07), (3, 0.0011542382), (8, 4.81058e-08)]\n",
            "affect [(3, 0.001203329)]\n",
            "liner [(6, 0.00013691848)]\n",
            "opera [(7, 0.00026346312), (9, 0.00075756875)]\n",
            "flip [(5, 0.0013903213)]\n",
            "tar [(1, 0.0001205969), (2, 3.038483e-08), (3, 0.0012123003)]\n",
            "pout [(0, 1.7829084e-06), (2, 8.431873e-06), (4, 5.6337285e-05), (6, 3.5075587e-05), (8, 4.7796555e-05)]\n",
            "noodle [(0, 0.00047730716), (8, 1.0713768e-08)]\n",
            "coma [(9, 0.0013519054)]\n",
            "flock [(7, 3.0545646e-06), (8, 0.00031068924)]\n",
            "spell [(9, 0.0018857674)]\n",
            "limbo [(0, 3.446211e-07), (1, 2.3491907e-07), (2, 5.233913e-07), (3, 1.1387116e-07), (4, 8.137965e-08), (5, 2.8792604e-07), (6, 1.619951e-06), (7, 3.247797e-07), (8, 3.9033748e-07), (9, 0.001225697)]\n",
            "gag [(6, 0.0002591127)]\n",
            "mace [(6, 9.4094976e-05)]\n",
            "sec [(9, 0.0014654984)]\n",
            "lock [(6, 0.0005246102)]\n",
            "bleak [(0, 4.21116e-08), (3, 0.0005211304), (5, 2.2470745e-08), (6, 1.1980924e-08), (7, 3.4553878e-08)]\n",
            "lean [(9, 0.0014095057)]\n",
            "elder [(7, 3.7410229e-07), (9, 0.0019040537)]\n",
            "cock [(6, 0.00056287344)]\n",
            "steep [(5, 1.4970666e-05), (6, 0.00042813824)]\n",
            "cot [(4, 1.1103132e-05), (5, 0.001167333), (7, 2.3838265e-05)]\n",
            "peck [(0, 5.2967203e-05), (1, 0.00013638924), (2, 5.1424802e-05), (3, 3.7589012e-05), (4, 4.4126373e-05), (5, 0.001177529), (6, 3.1617757e-05), (7, 2.8807328e-05), (8, 7.0086615e-05), (9, 6.433589e-05)]\n",
            "chop [(4, 0.0006254767), (8, 2.8752586e-06)]\n",
            "darn [(1, 0.0020275256)]\n",
            "page [(0, 0.0002781698), (2, 2.0128075e-06), (4, 0.00023704412)]\n",
            "strand [(0, 5.4320746e-05), (1, 1.5716229e-05), (2, 2.6274962e-05), (3, 6.6712644e-05), (4, 1.2946188e-05), (5, 5.137485e-05), (6, 1.7224887e-05), (7, 2.3565619e-05), (8, 1.6166923e-05), (9, 2.003864e-05)]\n",
            "butt [(2, 0.00083426124)]\n",
            "bongo [(2, 6.0459215e-06), (4, 3.9372903e-08), (5, 1.607996e-08), (7, 1.2932502e-07), (8, 3.6589007e-08), (9, 0.00054662017)]\n",
            "meal [(6, 0.0005592097)]\n",
            "tip [(0, 5.052253e-05), (2, 0.0002892983), (6, 0.00011855829), (8, 0.00016181555)]\n",
            "mint [(2, 0.00045053737), (6, 2.777393e-08)]\n",
            "paste [(3, 0.00091996655), (6, 3.8048368e-06), (7, 0.00011518856)]\n",
            "bank [(1, 0.0022514432), (2, 3.7433335e-08), (4, 3.851872e-06), (6, 0.00010325869), (8, 8.053145e-05)]\n",
            "undone [(0, 4.4715805e-05), (1, 9.496854e-05), (2, 6.6562345e-05), (3, 8.735498e-05), (4, 3.5315847e-05), (5, 0.00011887077), (6, 2.3853458e-05), (7, 5.215816e-05), (8, 4.3270993e-05), (9, 5.7073445e-05)]\n",
            "rent [(6, 0.00056688685)]\n",
            "spit [(1, 2.460626e-07), (7, 0.00019425328), (9, 0.0015155356)]\n",
            "stir [(1, 0.0018619731)]\n",
            "tower [(6, 0.0006610094)]\n",
            "pool [(7, 0.00069092336)]\n",
            "incense [(0, 4.1858973e-05), (1, 0.00010245268), (2, 7.21904e-05), (3, 7.023114e-05), (4, 3.0305295e-05), (5, 0.00010618753), (6, 3.25433e-05), (7, 7.4364936e-05), (8, 3.745014e-05), (9, 9.3453855e-05)]\n",
            "stud [(0, 0.00016607951), (2, 6.4714455e-05), (3, 0.0007645874), (8, 0.00017321476)]\n",
            "dent [(6, 4.1094234e-05), (7, 0.00085935293), (8, 4.2535694e-06)]\n",
            "temporal [(6, 3.518863e-05), (7, 0.0004560397)]\n",
            "bound [(6, 2.2253489e-05), (7, 0.00080567825)]\n",
            "commune [(0, 5.1505733e-05), (1, 5.3722408e-05), (2, 3.093881e-05), (3, 0.00010689368), (4, 4.928045e-05), (5, 8.384942e-05), (6, 4.5457076e-05), (7, 6.190616e-05), (8, 4.0038256e-05), (9, 4.5619625e-05)]\n",
            "boom [(0, 1.8209274e-08), (1, 0.003602115), (4, 2.603538e-07), (7, 7.505469e-05)]\n",
            "prop [(0, 6.374671e-05), (1, 9.926882e-05), (2, 5.4422067e-05), (3, 9.7964104e-05), (4, 6.466726e-05), (5, 0.0002000529), (6, 7.021748e-05), (7, 6.547204e-05), (8, 7.0014336e-05), (9, 0.00015236564)]\n",
            "egg [(9, 0.0035653121)]\n",
            "pen [(4, 7.47773e-06), (5, 0.0020797274), (9, 1.6822743e-05)]\n",
            "tuna [(9, 0.0031684937)]\n",
            "press [(0, 1.5778062e-08), (2, 2.953038e-07), (6, 0.00074685796), (7, 7.334877e-07)]\n",
            "converse [(0, 4.759002e-05), (1, 8.834019e-05), (2, 4.2909658e-05), (3, 3.9756957e-05), (4, 3.291485e-05), (5, 4.8529342e-05), (6, 1.835028e-05), (7, 2.4489813e-05), (8, 3.967533e-05), (9, 4.67257e-05)]\n",
            "swarm [(0, 0.00034997988), (5, 8.14412e-05), (6, 9.1453076e-05), (8, 8.001643e-08), (9, 6.272706e-05)]\n",
            "supply [(8, 0.0005931811)]\n",
            "bail [(1, 0.0029114233), (5, 1.1416631e-08)]\n",
            "file [(1, 0.002324555), (2, 3.9915964e-08), (7, 0.00028987686)]\n",
            "bay [(1, 0.0026371563), (9, 1.6540196e-07)]\n",
            "tart [(0, 0.00028536833), (1, 1.5760707e-08), (2, 1.0788746e-07), (4, 2.0176684e-07), (5, 0.00028009448), (6, 3.7452264e-08), (7, 1.6415978e-08), (8, 8.468684e-08), (9, 0.0011138637)]\n",
            "barker [(0, 8.460552e-07), (1, 1.5395905e-06), (2, 9.900381e-07), (5, 0.0002040262), (7, 2.261028e-06), (8, 1.4573986e-05), (9, 4.3988976e-07)]\n",
            "repent [(0, 6.0376533e-06), (1, 0.0023682404), (5, 1.9944634e-06), (7, 1.625471e-08), (8, 1.5191749e-05)]\n",
            "count [(2, 0.00079106766)]\n",
            "jerk [(0, 0.00046592767), (8, 0.0003350572)]\n",
            "lash [(4, 3.5159414e-07), (9, 0.0010518956)]\n",
            "deuce [(6, 3.095811e-07), (7, 0.00017822334), (8, 0.00016802437)]\n",
            "buffet [(0, 0.0010379396), (6, 4.7642665e-08), (7, 1.9045121e-06), (9, 1.473761e-07)]\n",
            "pot [(8, 1.830379e-07), (9, 0.0030180612)]\n",
            "pod [(3, 5.92762e-06), (6, 6.3885736e-08), (7, 0.0011742271)]\n",
            "sack [(3, 0.0022243625)]\n",
            "rally [(4, 0.00082627166)]\n",
            "lining [(3, 0.0015279008), (7, 3.9171617e-05)]\n",
            "dresser [(0, 0.00064493186), (1, 3.8947476e-07), (2, 5.8923993e-06), (3, 1.0655241e-06), (4, 6.8238364e-07), (5, 1.3887715e-06), (6, 0.00016137109), (7, 1.0213766e-06), (8, 5.03766e-07), (9, 0.00029664583)]\n",
            "vice [(9, 0.0009906257)]\n",
            "taxis [(0, 5.5329827e-05), (1, 0.00015128506), (2, 3.0503918e-05), (3, 0.00012757168), (4, 2.3964134e-05), (5, 9.4366726e-05), (6, 2.0052805e-05), (7, 3.241497e-05), (8, 3.184824e-05), (9, 2.6314032e-05)]\n",
            "smelt [(0, 7.18359e-05), (1, 3.1404994e-05), (2, 5.6935416e-05), (3, 5.8597154e-05), (4, 4.4675355e-05), (5, 5.0854334e-05), (6, 5.46739e-05), (7, 2.5608624e-05), (8, 1.611371e-05), (9, 5.6627516e-05)]\n",
            "tap [(2, 5.521808e-05), (8, 0.0004653688), (9, 4.5470682e-07)]\n",
            "cocktail [(7, 0.001106778)]\n",
            "bossy [(0, 5.274008e-05), (1, 0.00016864968), (2, 5.3591717e-05), (3, 2.4916379e-05), (4, 0.00014200615), (5, 0.00020023537), (6, 6.417968e-05), (7, 3.4365916e-05), (8, 7.315199e-05), (9, 3.2680327e-05)]\n",
            "hop [(2, 1.3520167e-06), (3, 0.0035659545)]\n",
            "intent [(4, 4.151613e-06), (5, 0.00010600641), (7, 0.0010080872)]\n",
            "mat [(5, 5.352042e-05), (7, 0.0010526124)]\n",
            "bear [(2, 3.0896117e-05), (3, 0.002148875), (6, 0.00034569373)]\n",
            "frail [(2, 5.270368e-07), (3, 2.75422e-07), (7, 0.0008174143)]\n",
            "jumper [(0, 0.00019773976), (3, 0.0009959835), (6, 5.542114e-05)]\n",
            "plight [(0, 0.00011186029), (1, 7.607983e-05), (2, 8.1074875e-05), (3, 0.000106111205), (4, 5.7694633e-05), (5, 7.5917116e-05), (6, 2.461067e-05), (7, 0.00012418405), (8, 1.688746e-05), (9, 0.000102574)]\n",
            "size [(0, 0.0017431171)]\n",
            "chap [(4, 0.00072813034)]\n",
            "calf [(2, 0.00043808186), (8, 0.00017289854), (9, 0.0007766583)]\n",
            "vault [(5, 0.0029017394)]\n",
            "bop [(4, 1.3477916e-08), (8, 1.201014e-08), (9, 0.00027748465)]\n",
            "refuse [(4, 0.00081103726)]\n",
            "gobble [(0, 6.5621636e-05), (1, 0.00015898749), (2, 2.897391e-05), (3, 0.00025689165), (4, 5.3948566e-05), (5, 0.0026393088), (6, 3.290418e-05), (7, 0.00030781757), (8, 3.9092647e-05), (9, 0.0023785233)]\n",
            "jar [(2, 3.407043e-05), (7, 0.0014918176)]\n",
            "tattoo [(8, 1.8314633e-05), (9, 0.0040315106)]\n",
            "tit [(0, 0.00013422544), (1, 0.00018825411), (2, 0.00015965024), (3, 5.111812e-05), (4, 0.00022163677), (5, 0.000259596), (6, 0.00015811367), (7, 8.830826e-05), (8, 4.8199832e-05), (9, 0.00015608288)]\n",
            "roach [(4, 0.00028005277), (6, 2.4965091e-05), (7, 0.00086267473)]\n",
            "pussy [(3, 0.0035149343)]\n",
            "cricket [(0, 0.0009286917), (2, 0.00013881756), (3, 3.1159242e-08), (4, 3.926583e-05), (8, 3.0149859e-05)]\n",
            "mill [(3, 1.0549162e-07), (7, 0.0014343113)]\n",
            "mode [(0, 3.6051338e-06), (1, 1.2798282e-06), (2, 1.4739403e-06), (3, 5.37438e-06), (4, 1.6648672e-06), (5, 3.293474e-06), (6, 7.68376e-06), (7, 4.454698e-06), (8, 2.4985277e-06), (9, 0.0033648312)]\n",
            "drill [(7, 0.0015068216)]\n",
            "lawn [(6, 0.0017517536)]\n",
            "snuff [(0, 6.0266688e-05), (1, 2.5300405e-05), (2, 7.0753485e-05), (3, 9.389222e-05), (4, 5.8487836e-05), (5, 6.170758e-05), (6, 8.387557e-05), (7, 4.611914e-05), (8, 5.092155e-05), (9, 0.00050185015)]\n",
            "exploit [(4, 3.2166547e-05), (6, 0.0002532108), (7, 0.00093784963)]\n",
            "desert [(1, 0.0046808906)]\n",
            "verse [(0, 1.0495951e-08), (2, 1.4363481e-05), (3, 0.0028625978)]\n",
            "shiver [(0, 3.81648e-08), (1, 2.7393073e-05), (2, 0.00020503603), (3, 1.1187473e-07), (4, 0.00025224194), (5, 5.9040544e-06), (6, 7.7779156e-08), (7, 0.0002533391), (8, 1.6279044e-07), (9, 1.193463e-07)]\n",
            "ground [(5, 0.00082018325), (6, 9.834584e-07), (7, 0.0019704946)]\n",
            "stick [(0, 0.00018248374), (4, 0.0010835183), (7, 0.00028547723)]\n",
            "palm [(2, 0.0011121801)]\n",
            "hatch [(9, 0.0040055597)]\n",
            "stake [(0, 1.5014316e-05), (1, 0.0010763159), (2, 0.00015253064), (3, 0.00016176817), (4, 0.000106640364), (6, 7.666574e-06), (8, 9.148029e-05)]\n",
            "funky [(9, 0.00083129166)]\n",
            "pipe [(0, 0.0002613545), (2, 0.00066803774), (6, 0.0003375267)]\n",
            "husky [(0, 0.00010781274), (6, 0.0001444824), (9, 0.00013052474)]\n",
            "dove [(2, 0.00108623)]\n",
            "bowl [(2, 0.0011597569), (4, 0.00018733196)]\n",
            "felon [(1, 0.004160611), (2, 1.0970565e-05), (3, 7.3308154e-05), (6, 0.00022293073)]\n",
            "tear [(3, 0.003630282)]\n",
            "clip [(6, 1.2886653e-05), (7, 0.001620224)]\n",
            "sling [(0, 4.6581277e-05), (1, 1.6543256e-05), (2, 6.359363e-05), (3, 5.418586e-05), (4, 4.719761e-05), (5, 6.190226e-05), (6, 0.000108456974), (7, 0.0012324827), (8, 4.6272056e-05), (9, 0.0001156266)]\n",
            "flatter [(0, 6.778286e-05), (1, 0.00024059684), (2, 0.00014933213), (3, 4.8064692e-05), (4, 0.00069632375), (5, 7.052208e-05), (6, 2.1911761e-05), (7, 4.4507207e-05), (8, 0.00010320927), (9, 3.924988e-05)]\n",
            "gull [(0, 0.0001040488), (1, 0.000115750176), (2, 5.194372e-05), (3, 9.6739626e-05), (4, 3.9570135e-05), (5, 6.6243745e-05), (6, 3.8781138e-05), (7, 1.8104629e-05), (8, 2.9754485e-06), (9, 9.371526e-05)]\n",
            "bolt [(9, 0.0052196975)]\n",
            "arm [(0, 0.00038682314), (2, 0.0012239788), (3, 0.0015750896), (9, 0.00091369136)]\n",
            "frog [(1, 0.00013229185), (3, 0.00037802782), (7, 0.0019386503)]\n",
            "bar [(6, 0.0015708661)]\n",
            "novel [(0, 1.40581815e-05), (1, 1.4573901e-05), (2, 4.3278774e-06), (6, 0.00021626029), (7, 0.0010545437), (8, 0.00022170738)]\n",
            "stamina [(0, 2.8116054e-05), (2, 8.176953e-05), (5, 1.0937777e-08), (6, 0.00039644868), (7, 9.647416e-06), (8, 0.0003955357)]\n",
            "stunt [(2, 0.00064890867), (3, 2.3488267e-08), (6, 0.00057811453)]\n",
            "rape [(3, 1.517891e-08), (4, 3.5485566e-05), (5, 4.0084713e-05), (6, 0.0005253111), (7, 0.0012315197)]\n",
            "wax [(9, 0.0036833964)]\n",
            "shy [(3, 0.0036841747)]\n",
            "foil [(2, 0.00042955845), (4, 2.4988816e-05), (9, 0.0011447072)]\n",
            "tick [(0, 6.487137e-08), (1, 9.11309e-06), (2, 1.4711141e-07), (3, 6.5244253e-06), (4, 1.4915805e-06), (5, 1.2021044e-07), (6, 0.0019986373), (7, 1.1865595e-07), (8, 0.00010649269), (9, 1.1721855e-05)]\n",
            "weed [(7, 1.4968359e-06), (8, 0.0010977101)]\n",
            "tense [(2, 9.171899e-06), (4, 0.00026089553), (6, 2.2551681e-08), (8, 0.0007406947)]\n",
            "poker [(2, 0.0014157979), (8, 1.2266962e-08)]\n",
            "pupil [(2, 0.00090402836), (5, 0.0011845669)]\n",
            "bob [(6, 0.0013967896)]\n",
            "troll [(0, 2.8586066e-05), (4, 2.7045864e-08), (6, 2.824726e-07), (7, 0.0022496094)]\n",
            "mow [(4, 0.0014419314)]\n",
            "brake [(2, 0.0017655524), (3, 0.00018136174)]\n",
            "pad [(4, 0.0015918883)]\n",
            "bunk [(3, 1.7227636e-08), (5, 0.005480352)]\n",
            "ounce [(0, 8.0056394e-05), (3, 0.0042755273), (7, 7.264754e-05), (9, 2.4267043e-05)]\n",
            "plane [(1, 0.008335812), (2, 8.866468e-06), (3, 7.76305e-08), (6, 7.3835736e-08), (9, 0.00028089964)]\n",
            "squash [(0, 0.00012836407), (1, 0.00024242884), (2, 0.00020389687), (3, 0.00013259196), (4, 0.00023975575), (5, 0.0005002568), (6, 0.00014145146), (7, 0.000109016735), (8, 0.00021524038), (9, 0.00027770118)]\n",
            "mum [(8, 0.0012012456)]\n",
            "scrap [(0, 1.148755e-07), (1, 1.6943191e-07), (2, 1.3194428e-05), (3, 4.2331635e-07), (4, 1.2891779e-07), (5, 4.6732697e-07), (6, 2.964791e-07), (7, 0.0018968232), (8, 6.0059756e-06), (9, 1.0987003e-07)]\n",
            "gill [(1, 1.698694e-07), (3, 3.9855888e-05), (7, 2.0283242e-05), (9, 9.999602e-08)]\n",
            "grate [(6, 0.00011712599), (9, 0.0026400466)]\n",
            "caddy [(0, 5.823626e-07), (1, 1.5022359e-06), (2, 1.7652097e-06), (3, 6.3939956e-07), (4, 9.4054417e-07), (5, 1.723408e-06), (6, 1.0480812e-07), (7, 4.3804303e-06), (8, 1.1901141e-06), (9, 0.004516268)]\n",
            "compound [(7, 0.0020491886)]\n",
            "lay [(6, 5.497742e-05), (8, 0.0009944349)]\n",
            "drone [(9, 0.006046283)]\n",
            "hind [(4, 8.062463e-06), (5, 0.0033646438), (7, 4.951727e-05)]\n",
            "pitch [(6, 0.0008844612)]\n",
            "mail [(5, 0.0056349114)]\n",
            "soil [(9, 0.0062653786)]\n",
            "shin [(2, 7.4038326e-06), (4, 1.6040584e-06), (7, 0.00033564377), (8, 1.5708376e-07), (9, 0.0010497229)]\n",
            "revere [(0, 8.081119e-05), (1, 5.01285e-05), (2, 3.3995748e-05), (3, 2.7400229e-05), (4, 4.1222862e-05), (5, 0.0001125258), (6, 8.4452795e-06), (7, 4.1505384e-05), (8, 1.618394e-05), (9, 1.0827135e-06)]\n",
            "midst [(0, 2.1807075e-08), (2, 1.6376723e-07), (7, 0.0023514752)]\n",
            "affected [(3, 1.3073428e-06), (6, 5.432618e-07), (7, 0.0023227746)]\n",
            "hiding [(0, 0.0028904388)]\n",
            "lug [(6, 0.00040343314), (7, 0.00031123016)]\n",
            "bull [(2, 0.0012745555), (4, 0.0006296854), (6, 2.0128968e-05), (9, 1.9105453e-05)]\n",
            "spat [(0, 0.00018134029), (2, 0.00082722364)]\n",
            "brush [(7, 0.0032385124), (9, 2.1459858e-08)]\n",
            "lying [(4, 0.0018742587)]\n",
            "hitch [(0, 3.581525e-05), (1, 0.00010219087), (2, 6.8147456e-05), (3, 0.00011368719), (4, 0.0002164138), (5, 0.00013311612), (6, 7.1627655e-05), (7, 8.8645786e-05), (8, 0.0010208037), (9, 0.00010462683)]\n",
            "tire [(6, 0.001927553)]\n",
            "jerky [(0, 0.00012444712), (1, 0.0004906298), (2, 0.00018915051), (3, 0.00034614894), (4, 0.00015814308), (5, 0.00040372857), (6, 0.00016063562), (7, 9.53908e-05), (8, 0.00019590401), (9, 0.0019192711)]\n",
            "toaster [(3, 9.125078e-07), (8, 2.1473045e-06), (9, 0.0072492515)]\n",
            "wise [(4, 0.0016737579), (6, 0.00030701866), (9, 4.6861005e-05)]\n",
            "hue [(0, 0.00019371179), (1, 0.00030679035), (2, 6.680388e-05), (3, 0.00017704058), (4, 2.9879648e-05), (5, 3.955044e-05), (6, 6.0129365e-05), (7, 0.00010939416), (8, 3.757329e-06), (9, 0.00013492038)]\n",
            "flush [(3, 0.0033602873)]\n",
            "flaw [(0, 0.00083653146), (2, 0.0013208744), (6, 0.00030193667)]\n",
            "boil [(2, 0.0018589543), (6, 7.421877e-05)]\n",
            "stoop [(0, 6.50189e-08), (1, 0.0038144959), (2, 2.7797105e-07), (3, 1.3934585e-08), (4, 8.1316664e-08), (5, 7.278411e-08), (6, 6.16846e-06), (7, 6.10548e-08), (8, 0.0006720568), (9, 1.2676867e-08)]\n",
            "hull [(0, 0.00022390488), (1, 0.00016934851), (2, 7.073898e-05), (3, 0.00031123075), (4, 3.455327e-05), (5, 0.00018115327), (6, 9.0124304e-05), (7, 0.00010858396), (8, 4.985864e-05), (9, 0.004815642)]\n",
            "bowler [(0, 0.00014473824), (1, 0.00017875477), (2, 0.00029820393), (3, 0.00025014867), (4, 0.000117984404), (5, 0.0002307671), (6, 6.843891e-05), (7, 0.000116615745), (8, 0.00012519002), (9, 0.00012114144)]\n",
            "cramp [(0, 2.6906136e-07), (1, 1.7764273e-07), (2, 7.7598037e-07), (3, 5.1039372e-08), (4, 7.627001e-07), (5, 4.7607358e-07), (6, 7.53419e-07), (7, 5.4024742e-08), (8, 7.8078693e-07), (9, 0.0072620423)]\n",
            "spoke [(7, 0.0030009998)]\n",
            "staple [(0, 3.6656417e-08), (3, 3.809004e-08), (4, 0.00010578575), (5, 2.7255597e-08), (6, 0.0003956387), (7, 0.00039579623), (8, 4.5672834e-08)]\n",
            "jam [(6, 0.0021792497)]\n",
            "capital [(0, 0.0034232151), (7, 4.785485e-05)]\n",
            "titanic [(2, 0.00026775093)]\n",
            "spade [(0, 5.2578875e-05), (1, 1.4235177e-06), (2, 1.7591507e-05), (3, 0.0002972992), (4, 4.806522e-06), (5, 0.00032861548), (6, 1.6826532e-05), (7, 3.0236066e-05), (8, 3.304506e-05), (9, 0.0010212731)]\n",
            "mood [(0, 0.0024673066), (7, 0.0010231788)]\n",
            "hamper [(0, 0.00028546224), (1, 0.00019618934), (2, 0.0001907002), (3, 0.0004912298), (4, 0.00016717837), (5, 0.00037740896), (6, 0.00014213569), (7, 0.00016061356), (8, 0.0001426294), (9, 0.00010163231)]\n",
            "fan [(9, 0.008426258)]\n",
            "scram [(4, 2.9238788e-06), (6, 0.0021548038)]\n",
            "keen [(3, 2.0944478e-08), (4, 0.001149193)]\n",
            "gram [(0, 3.2524432e-07), (3, 0.0054064714), (6, 2.1916785e-08)]\n",
            "wrinkle [(0, 0.003150887), (1, 8.251282e-08), (2, 8.310938e-08), (3, 1.6586185e-08), (4, 6.528823e-05), (5, 0.0003615994), (6, 5.2792284e-08), (7, 2.523959e-08), (8, 2.5990676e-07), (9, 1.241043e-07)]\n",
            "bride [(0, 0.0044672075)]\n",
            "bass [(2, 0.0025123793)]\n",
            "pug [(0, 5.966718e-05), (1, 0.00023592504), (2, 6.420454e-05), (3, 0.00018021346), (4, 6.543223e-05), (5, 0.0001295432), (6, 5.6573215e-05), (7, 1.9470499e-05), (8, 2.2739106e-05), (9, 0.0002201638)]\n",
            "rake [(9, 0.009591009)]\n",
            "mount [(1, 0.00909472)]\n",
            "rear [(6, 0.0024523132)]\n",
            "flight [(1, 0.010608399)]\n",
            "rush [(0, 2.587713e-05), (8, 0.0021501284)]\n",
            "rose [(6, 0.0013913817), (7, 0.0017821351)]\n",
            "yen [(7, 0.0031888376)]\n",
            "quack [(4, 3.9539995e-05), (7, 0.00054192817), (8, 0.004422557)]\n",
            "bluff [(4, 0.0023028979), (6, 2.8415968e-07)]\n",
            "strip [(3, 0.0070200674)]\n",
            "ban [(3, 0.007017052), (7, 3.4683893e-08)]\n",
            "cube [(1, 0.00041781142), (4, 3.59448e-05), (6, 0.002312662), (7, 6.5494364e-06), (9, 6.458979e-05)]\n",
            "glare [(0, 0.00017971506), (1, 0.0039873566), (2, 3.466982e-05), (3, 0.00031848773), (4, 4.670445e-05), (5, 0.00021895459), (6, 8.2770974e-05), (7, 0.00011139624), (8, 6.942193e-05), (9, 0.00037230353)]\n",
            "prior [(0, 1.0289486e-08), (5, 4.065909e-08), (7, 0.0036399562)]\n",
            "pitcher [(0, 7.233174e-05), (1, 0.0056666574), (5, 1.7837476e-07), (7, 2.6015561e-08), (8, 0.0006718402)]\n",
            "settle [(0, 0.004389331)]\n",
            "bush [(1, 0.010672639)]\n",
            "slack [(3, 0.00031664516), (4, 0.0026314433), (8, 4.1990293e-06)]\n",
            "jade [(0, 1.4009469e-08), (1, 0.0105259), (5, 1.0606421e-05), (6, 1.21545165e-08)]\n",
            "shock [(4, 0.0011754931), (7, 0.0030160686)]\n",
            "steer [(6, 0.002442524)]\n",
            "hide [(5, 0.011240267), (7, 1.6110576e-07)]\n",
            "spank [(9, 0.008886333)]\n",
            "pet [(2, 2.125789e-05), (9, 0.014420888)]\n",
            "bat [(4, 3.836024e-06), (9, 0.0102116205)]\n",
            "rubber [(9, 0.013832708)]\n",
            "toast [(0, 4.2174374e-08), (7, 0.0042803762)]\n",
            "coil [(3, 0.0065920204)]\n",
            "relief [(6, 0.002958758)]\n",
            "crab [(0, 5.1392316e-08), (2, 0.0038255432), (3, 1.42523e-07)]\n",
            "buffer [(0, 0.00041829763), (1, 0.00045367147), (2, 0.00036413793), (3, 0.00046833686), (4, 0.0002490233), (5, 0.00046635268), (6, 0.00027212047), (7, 0.00053273165), (8, 0.00031688018), (9, 0.0005780073)]\n",
            "low [(2, 0.001645508), (6, 0.0007367748), (7, 0.0019887942)]\n",
            "liver [(5, 0.010261956), (8, 9.393954e-06)]\n",
            "cow [(6, 0.0033388496)]\n",
            "buff [(7, 0.00028897074), (8, 0.0018796029)]\n",
            "rejoin [(0, 0.0003555631), (1, 0.00044564955), (2, 0.0003539888), (3, 0.00017430412), (4, 0.00015590258), (5, 0.00026062646), (6, 0.00016137556), (7, 0.00023036756), (8, 0.00022739184), (9, 0.0004057569)]\n",
            "punch [(4, 0.002706765)]\n",
            "loaf [(9, 0.011611253)]\n",
            "chink [(0, 3.059715e-05), (1, 9.4573615e-08), (2, 2.6067954e-05), (5, 0.00023185837), (6, 1.9869012e-05), (7, 0.00061527564), (9, 0.0004052474)]\n",
            "blaze [(0, 0.00078501704), (1, 0.0008658905), (4, 0.00013701685), (5, 0.0011143141), (7, 0.0013186116), (8, 3.605184e-05)]\n",
            "cap [(9, 0.015320658)]\n",
            "scarf [(0, 8.2697505e-07), (1, 0.00015510696), (2, 0.051317487), (4, 0.00022176997), (5, 1.464678e-08), (7, 0.0066592377), (8, 0.00046589167), (9, 6.4868993e-07)]\n",
            "putter [(0, 0.00010072069), (1, 0.0008711147), (2, 0.00023071253), (3, 0.05425922), (4, 2.4253322e-05), (5, 0.0044063446), (6, 0.0006609829), (7, 3.8107974e-05), (8, 0.0012734827), (9, 6.608203e-05)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4Vb2-O-ib-c",
        "outputId": "e489aa83-5605-452b-d966-eb39d44d96ac"
      },
      "source": [
        "# let's look at classifications of documents containing an ambiguous word\n",
        "# \"slick\" has only two topics\n",
        "# slick [(3, 4.517052e-05), (7, 9.48455e-06)]\n",
        "\n",
        "slick_df = rice[rice['probe']=='slick']\n",
        "\n",
        "print(\"Topic 3\")\n",
        "for term, score in model.get_topic_terms(3):\n",
        "  print(rice_dictionary[term])\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Topic 7\")\n",
        "for term, score in model.get_topic_terms(7):\n",
        "  print(rice_dictionary[term])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 3\n",
            "going\n",
            "it\n",
            "come\n",
            "fire\n",
            "racket\n",
            "mess\n",
            "beyond\n",
            "don\n",
            "time\n",
            "fetch\n",
            "\n",
            "Topic 7\n",
            "it\n",
            "come\n",
            "time\n",
            "representing\n",
            "built-in\n",
            "welcome\n",
            "small\n",
            "allah\n",
            "pockets\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53ibusz7jbEK",
        "outputId": "1d6903e7-49b9-456e-afde-75e9c745da1f"
      },
      "source": [
        "# now we want to encode all our documents using LdaModel\n",
        "threes = []\n",
        "sevens = []\n",
        "for i, row in slick_df.sample(n=10).iterrows():\n",
        "  document_text = row['line']\n",
        "  # get doc-topic representation\n",
        "  doc_to_topic_rep = ambig_lda.get_document_topics(bow=rice_corpus[i])\n",
        "  _, topic_3_score = doc_to_topic_rep[3]\n",
        "  _, topic_7_score = doc_to_topic_rep[7]\n",
        "  # compare the probabilities of our two \"slick\" topics\n",
        "  print(topic_3_score, topic_7_score)\n",
        "  # does the text align with our intuitions?\n",
        "  if topic_3_score > topic_7_score:\n",
        "    threes.append(document_text)\n",
        "  elif topic_7_score > topic_3_score:\n",
        "    sevens.append(document_text)\n",
        "\n",
        "print()\n",
        "print(\"These are are 'Topic 3' uses of 'slick':\")\n",
        "for doc in threes:\n",
        "  print(doc)\n",
        "print()\n",
        "print(\"These are 'Topic 7' uses of 'slick:\")\n",
        "for doc in sevens:\n",
        "  print(doc)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0066689197 0.006669977\n",
            "0.61245483 0.008335385\n",
            "0.011114817 0.23883118\n",
            "0.0030309826 0.3115274\n",
            "0.0043484955 0.1723827\n",
            "0.18834357 0.66434586\n",
            "0.01000216 0.5434803\n",
            "0.005557318 0.0055559804\n",
            "0.10803135 0.0055585233\n",
            "0.0066695143 0.006667007\n",
            "\n",
            "These are are 'Topic 3' uses of 'slick':\n",
            "I 'm gon na hate to have to give you up , slick . ( KARR )\n",
            "But I 've got this guy , he 's just come from America , he 's really slick .\n",
            "Nothing . It might be a slick way to get to know her . Why ?\n",
            "Its tyres are as slick as the law allows and you get racing suspension .\n",
            "\n",
            "These are 'Topic 7' uses of 'slick:\n",
            "Okay , we 're gon na get our show back on the air ... ... and were not gon na be intimidated by any slick executive types .\n",
            "Still just as slick as a horsehair couch .\n",
            "Oil slick to port .\n",
            "Pretty slick .\n",
            "My mind was slick , my temper was too quick\n",
            "Or we can slick on it , oil slick\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcHbYklemcA8"
      },
      "source": [
        "It looks like \"slick\" can be used in a more positive way, and a more negative way! But, we might need to do more digging into this ambiguous words dataset and wordnet to really say."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzUA_YA5lRIF"
      },
      "source": [
        "### As you can see, topic modelling algorithms like LDA do well with large amounts of data, but struggle with short documents just like Latent Semantic Analysis (LSA)\n",
        "\n",
        "Every single model will struggle with short documents! And people do too. But people are better at it. Can you think of why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3bVP3rmlfgY"
      },
      "source": [
        "# Next week:\n",
        "\n",
        "## 1. Guest lecture by Liz on Monday! Please attend, she is awesome :)\n",
        "## 2. Learning more about (neural) contextual language models"
      ]
    }
  ]
}