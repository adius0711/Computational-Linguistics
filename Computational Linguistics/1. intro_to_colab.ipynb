{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n91vpEKqvsHY"
   },
   "source": [
    "# Google Colab Basics\n",
    "\n",
    "Google Colab is a browser-based platform that allows you to run Python code from the web. It is very similar to Jupyter, which you can use locally on your computer or in the cloud. Basically, a notebook will behave just as if you were starting a new Terminal ([Windows](https://docs.microsoft.com/en-us/windows/terminal/get-started), [Mac](https://support.apple.com/guide/terminal/welcome/mac), [Linux](https://ubuntu.com/tutorials/command-line-for-beginners#1-overview)) window on your computer.\n",
    "\n",
    "The fundamental units of a Colab notebook are _cells_ and their outputs. A _cell_ is just a code block that contains some Python, which behave exactly as regular Python code. A cell's outputs can be stored within the notebook and are just like storing variables in the terminal. If you have ever used  `python` in Terminal, or run `ipython` to get a more interactive, user-friendly python, you are basically doing the same thing as a notebook.\n",
    "\n",
    "The main thing that distinguishes between a notebook and a python (`.py`) file is whether the notebook contains Markdown, javascript, and HTML. In this course, we will use \"text cells\" that you can use Markdown for to answer questions _without_ code, and code cells which will rely on Python to answer questions that _require_ code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SatTMPR_5ysC"
   },
   "outputs": [],
   "source": [
    "# This is a code cell. In it, you can write any valid Python.\n",
    "# You do not need to double click to see the contents of this cell.\n",
    "# Remember, the # means that this is a \"comment\" so in this cell nothing will be output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6K2RTXdE57gx"
   },
   "source": [
    "This is a text cell. In it, you can write any valid Markdown. Double click on this cell to see the contents of the markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qZvmbqav2w1",
    "outputId": "5093a64a-ace7-49e7-8ef8-1acec3bbe60a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations! You've run your first code snippet in Colab!\n"
     ]
    }
   ],
   "source": [
    "#Google Colab is a browser-based platform for running Python code. The interface is very similar to Jupyter.\n",
    "\n",
    "#To execute a code cell, press the 'play' button in the upper left corner, or hit Ctr + Enter\n",
    "print('Congratulations! You\\'ve run your first code snippet in Colab!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "id": "3tFTam29kD0s",
    "outputId": "d4001f6b-0e5a-44c8-831c-3386181d82af"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-c1516eaa499e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print('Congratulations! You\\'ve run your first code snippet in Colab!'\u001b[0m\n\u001b[0m                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "print('Congratulations! You\\'ve run your first code snippet in Colab!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jExSas9xCTF1"
   },
   "source": [
    "## Shell commands\n",
    "\n",
    "Colab also has a bash/shell environment. You can navigate through folders using exclamation points to indicate bash (terminal-style) code.\n",
    "\n",
    "If you are unfamiliar with shell commands, here is a brief overview:\n",
    "\n",
    "* [`ls`](https://linuxize.com/post/how-to-list-files-in-linux-using-the-ls-command/) shows you the contents of a folder\n",
    "* [`cd`](https://linuxize.com/post/basic-linux-commands/#changing-directory-cd-command) lets you <u>**c**</u>hange <u>**d**<u>irectories into any folder on the computer.\n",
    "* `less` followed by a filename (e.g., `less example.txt`) shows you the contents of a file on the computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvee9ZHxtSiN",
    "outputId": "8d7081ab-bb24-48a3-d0f1-bad208eefeb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgJrs1SskV4B",
    "outputId": "eadcd0c6-3a38-410a-feed-d085b489be6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin\t datalab  home\t lib64\topt\t    root  srv\t\t     tmp    var\n",
      "boot\t dev\t  lib\t media\tproc\t    run   sys\t\t     tools\n",
      "content  etc\t  lib32  mnt\tpython-apt  sbin  tensorflow-1.15.2  usr\n"
     ]
    }
   ],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcY5tK_n7v-5",
    "outputId": "0c4f5d22-532f-4d94-9bd7-16c6407ed75a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anscombe.json\t\t      mnist_test.csv\n",
      "california_housing_test.csv   mnist_train_small.csv\n",
      "california_housing_train.csv  README.md\n"
     ]
    }
   ],
   "source": [
    "!ls sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21SAN2LzkhZV",
    "outputId": "e273400f-5a42-4e71-bb46-2e6497c11a94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[?47h\u001b[?1h\u001b=\r",
      "\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"popu \blation\",\"households\",\"median_income\",\"median_house_value\"\r\n",
      "-114.310000,34.190000,15.000000,5612.000000,1283.000000,1015.000000,472.000000,1 \b.493600,66900.000000\r\n",
      "-114.470000,34.400000,19.000000,7650.000000,1901.000000,1129.000000,463.000000,1 \b.820000,80100.000000\r\n",
      "-114.560000,33.690000,17.000000,720.000000,174.000000,333.000000,117.000000,1.65 \b0900,85700.000000\r\n",
      "-114.570000,33.640000,14.000000,1501.000000,337.000000,515.000000,226.000000,3.1 \b91700,73400.000000\r\n",
      "-114.570000,33.570000,20.000000,1454.000000,326.000000,624.000000,262.000000,1.9 \b25000,65500.000000\r\n",
      "-114.580000,33.630000,29.000000,1387.000000,236.000000,671.000000,239.000000,3.3 \b43800,74000.000000\r\n",
      "-114.580000,33.610000,25.000000,2907.000000,680.000000,1841.000000,633.000000,2. \b676800,82400.000000\r\n",
      "-114.590000,34.830000,41.000000,812.000000,168.000000,375.000000,158.000000,1.70 \b8300,48500.000000\r\n",
      "-114.590000,33.610000,34.000000,4789.000000,1175.000000,3134.000000,1056.000000, \b2.178200,58400.000000\r\n",
      "-114.600000,34.830000,46.000000,1497.000000,309.000000,787.000000,271.000000,2.1 \b90800,48100.000000\n",
      "\u001b[K:\u001b[K^C\n"
     ]
    }
   ],
   "source": [
    "!less sample_data/california_housing_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aslBzZqLkqSt",
    "outputId": "c73d88b5-2370-4ae5-b2a7-a3c393da9fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6q2Nxgzdkxir",
    "outputId": "e963c87e-3019-4856-bb1b-ee9ab0057ead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n",
      "\u001b[K     |████████████████████████████████| 264 kB 5.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
      "Collecting fsspec>=2021.05.0\n",
      "  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n",
      "\u001b[K     |████████████████████████████████| 119 kB 47.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.4)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
      "Collecting huggingface-hub<0.1.0\n",
      "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 6.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 41.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: xxhash, huggingface-hub, fsspec, datasets\n",
      "Successfully installed datasets-1.11.0 fsspec-2021.8.1 huggingface-hub-0.0.16 xxhash-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LIEYew5DSyh"
   },
   "source": [
    "Now, make a file called `example.txt` that contains a short sentence, such as, \"The football team of Buffalo, NY is the Buffalo Bills.\"\n",
    "\n",
    "You can create this file in any text editor (TextEdit on Macs, Notepad on Windows, and your favorite for any Linux users here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "NV12Y_7xvU-8",
    "outputId": "78a83088-13f1-4b3c-b1cd-38d41c6e7e30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-a881958b-c83d-4712-a280-e4c3f83b9c56\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-a881958b-c83d-4712-a280-e4c3f83b9c56\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving abstracts.tsv to abstracts.tsv\n"
     ]
    }
   ],
   "source": [
    "#To upload a file from your local machine:\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xfO3-zv6Tib",
    "outputId": "01bbd806-f339-421a-93bc-6d9225bc3df9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Offensive language detection (OLD) has received increasing attention due to its societal impact. Recent work shows that bidirectional transformer based methods obtain impressive performance on OLD. However, such methods usually rely on large-scale well-labeled OLD datasets for model training. To address the issue of data/label scarcity in OLD, in this paper, we propose a simple yet effective domain adaptation approach to train bidirectional transformers. Our approach introduces domain adaptation (DA) training procedures to ALBERT, such that it can effectively exploit auxiliary data from source domains to improve the OLD performance in a target domain. Experimental results on benchmark datasets show that our approach, ALBERT (DA), obtains the state-of-the-art performance in most cases. Particularly, our approach significantly benefits underrepresented and under-performing classes, with a significant improvement over ALBERT.',\n",
       " 'Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.',\n",
       " 'We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.',\n",
       " \"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\",\n",
       " 'Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#once a file is uploaded to colab, you can read it into python:\n",
    "uploaded['abstracts.tsv'].decode('utf-8').split(\"\\n\")[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppXel3nVtbzA",
    "outputId": "aef3972a-bafb-4049-ff8e-23572dec9836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#To connect your google drive to colab:\n",
    "from google.colab import drive\n",
    "\n",
    "#note: colab will prompt you for an authorization code. Click the link that pops up and paste the code in the box below.\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POtGbxCptprO",
    "outputId": "d343dee5-56ff-4fba-a1b4-9d9f9640990b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n",
      "Teaching\n"
     ]
    }
   ],
   "source": [
    "#now you can access the files in your google drive from colab\n",
    "%cd drive/My Drive\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXbpJ7R5mVjq",
    "outputId": "19a0aa24-8eaa-4e06-b717-ecc8b9503857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intro_to_colab.ipynb  intro_to_python.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls Teaching/Fall2021/Computational\\ Linguistics/Lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-q368ksmmnqT",
    "outputId": "add2e58a-8327-46e2-8519-b70519d2da2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Teaching/Fall2021/Computational Linguistics/Lectures/supplementary_files\n"
     ]
    }
   ],
   "source": [
    "%cd Teaching/Fall2021/Computational\\ Linguistics/Lectures/supplementary_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CyBFreIfxNad",
    "outputId": "65f83db4-9330-41fd-98ac-efa413c4d3ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='abstracts.tsv' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "#once a file is uploaded to colab, you can read it into python:\n",
    "with open('abstracts.tsv','r') as example_file:\n",
    "  print(example_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FuZ8lEWcmz2n"
   },
   "outputs": [],
   "source": [
    "abstracts = open('abstracts.tsv', 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jyKD8cHm42V",
    "outputId": "9e655ae4-b1fa-4955-c905-29a43ec9fc22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Offensive language detection (OLD) has received increasing attention due to its societal impact. Recent work shows that bidirectional transformer based methods obtain impressive performance on OLD. However, such methods usually rely on large-scale well-labeled OLD datasets for model training. To address the issue of data/label scarcity in OLD, in this paper, we propose a simple yet effective domain adaptation approach to train bidirectional transformers. Our approach introduces domain adaptation (DA) training procedures to ALBERT, such that it can effectively exploit auxiliary data from source domains to improve the OLD performance in a target domain. Experimental results on benchmark datasets show that our approach, ALBERT (DA), obtains the state-of-the-art performance in most cases. Particularly, our approach significantly benefits underrepresented and under-performing classes, with a significant improvement over ALBERT.\\n',\n",
       " 'Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.\\n',\n",
       " 'We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.\\n',\n",
       " \"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\\n\",\n",
       " 'Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.\\n']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNFgIn5VD66j"
   },
   "source": [
    "### Package installation\n",
    "\n",
    "For example, NLTK: https://pypi.org/project/nltk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p17sEJa8uJMi"
   },
   "outputs": [],
   "source": [
    "#you can use pip to install packages\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDReOx1_Dx94"
   },
   "outputs": [],
   "source": [
    "#now you can import the package (note: you will need to reinstall packages everytime you start a new runtime)\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylYQeZwenciR"
   },
   "source": [
    "```\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print(word_tokenize(\"This is a sentence\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5u3qof4k8dub"
   },
   "source": [
    "## All of my numbers are messed up. How do I start over?\n",
    "\n",
    "You will need to restart the runtime. To get a completely clean slate, go to\n",
    "`Runtime > Factory reset runtime`. This will reset all of your cells to having never been run and will uninstall any new packages that you installed. \n",
    "\n",
    "If you want to just start over, do `Runtime > Restart runtime` instead.\n",
    "\n",
    "If you want to erase all of the output of those previously run cells, you should also go to `Edit > Clear all outputs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO8TFibiEEeu"
   },
   "source": [
    "## Many standard python packages are automatically installed when you start a Colab instance.\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDKVWYxjEKar"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcoKJGPBRBcZ"
   },
   "source": [
    "Everything you write in a previously-run cell will influence the next cell. So, every variable you include will be \"known\" to all subsequent cells. However, you should try to keep cells self-contained. For example, in our homework assignments we will have separate questions, which will all be answered within a single cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBVoII7sEih-"
   },
   "source": [
    "# About Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbtyLJH_dZVn"
   },
   "source": [
    "Markdown cells allow you to write simple, HTML-like text without a need for HTML tags. It can help make your notebook look nicer. Here, a Markdown (Text) cell in Colab lets us write _exposition_ about our decisions, _motivation_ for a particular analysis, or _summaries_ of the results of previous analyses. In some variants of Markdown, you can include fancy formatting, including LaTeX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUaUxrn0RaTw"
   },
   "source": [
    "To make pleasant-looking headings, use `###` before them. `##` will be a similar heading, but slightly larger, and `#` will be the largest heading.\n",
    "\n",
    "### A cute heading\n",
    "\n",
    "## Another cute one\n",
    "\n",
    "# A bigge boye heading\n",
    "\n",
    "If you want to write something in italics, you can use one asterisk \\* before and after what you want to italicize. For example: *this is a sentence*. If you use two \\*\\*, you will make boldface. For example: **this is also a sentence**. If you want to strike something out, you can use \\~\\~ before and after, à la: ~~Pretend you didn't see this sentence~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa9a5sSPR3A4"
   },
   "source": [
    "You can also embed fake code into your Markdown cells by using three backward ticks: \\`\\`\\`\n",
    "\n",
    "Double click on this cell to see how this looks!\n",
    "\n",
    "```\n",
    "list_of_words = ['This', 'is', 'a', 'sentence']\n",
    "for word in list_of_words:\n",
    "    print(word)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "041qbKn4dy1K"
   },
   "source": [
    "## $\\LaTeX$ in Markdown\n",
    "\n",
    "### Bayes' rule\n",
    "$p(A|B) = \\frac{p(B|A) * p(A)}{p(B)}$\n",
    "\n",
    "Using $\\LaTeX$ in Markdown may come in handy when you want to explain a formula you are trying to turn into code in later assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68YOwO7FS21a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDSMrkzHS7MN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i35Y9CsxS6-Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "FjuAK0LeS6lT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3tPujDgzpA3S",
    "outputId": "35a4ac71-bed7-4db5-c075-1db3b55bac50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anscombe.json\t\t      mnist_test.csv\n",
      "california_housing_test.csv   mnist_train_small.csv\n",
      "california_housing_train.csv  README.md\n"
     ]
    }
   ],
   "source": [
    "!ls /content/sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "TcjNFwR8o2Pm"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/sample_data/california_housing_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "niPafin7o_Q4",
    "outputId": "8f4cc4cc-fd9a-4330-c4c6-bb426897d3b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.31</td>\n",
       "      <td>34.19</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.4936</td>\n",
       "      <td>66900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.47</td>\n",
       "      <td>34.40</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8200</td>\n",
       "      <td>80100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.56</td>\n",
       "      <td>33.69</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.6509</td>\n",
       "      <td>85700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.64</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.1917</td>\n",
       "      <td>73400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.57</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9250</td>\n",
       "      <td>65500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  ...  median_income  median_house_value\n",
       "0    -114.31     34.19  ...         1.4936             66900.0\n",
       "1    -114.47     34.40  ...         1.8200             80100.0\n",
       "2    -114.56     33.69  ...         1.6509             85700.0\n",
       "3    -114.57     33.64  ...         3.1917             73400.0\n",
       "4    -114.57     33.57  ...         1.9250             65500.0\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ObTXYl0FpGK-",
    "outputId": "02e4957e-ada7-4e2f-affc-69bbd5a7949d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Offensive',\n",
       "  'language',\n",
       "  'detection',\n",
       "  '(OLD)',\n",
       "  'has',\n",
       "  'received',\n",
       "  'increasing',\n",
       "  'attention',\n",
       "  'due',\n",
       "  'to',\n",
       "  'its',\n",
       "  'societal',\n",
       "  'impact.',\n",
       "  'Recent',\n",
       "  'work',\n",
       "  'shows',\n",
       "  'that',\n",
       "  'bidirectional',\n",
       "  'transformer',\n",
       "  'based',\n",
       "  'methods',\n",
       "  'obtain',\n",
       "  'impressive',\n",
       "  'performance',\n",
       "  'on',\n",
       "  'OLD.',\n",
       "  'However,',\n",
       "  'such',\n",
       "  'methods',\n",
       "  'usually',\n",
       "  'rely',\n",
       "  'on',\n",
       "  'large-scale',\n",
       "  'well-labeled',\n",
       "  'OLD',\n",
       "  'datasets',\n",
       "  'for',\n",
       "  'model',\n",
       "  'training.',\n",
       "  'To',\n",
       "  'address',\n",
       "  'the',\n",
       "  'issue',\n",
       "  'of',\n",
       "  'data/label',\n",
       "  'scarcity',\n",
       "  'in',\n",
       "  'OLD,',\n",
       "  'in',\n",
       "  'this',\n",
       "  'paper,',\n",
       "  'we',\n",
       "  'propose',\n",
       "  'a',\n",
       "  'simple',\n",
       "  'yet',\n",
       "  'effective',\n",
       "  'domain',\n",
       "  'adaptation',\n",
       "  'approach',\n",
       "  'to',\n",
       "  'train',\n",
       "  'bidirectional',\n",
       "  'transformers.',\n",
       "  'Our',\n",
       "  'approach',\n",
       "  'introduces',\n",
       "  'domain',\n",
       "  'adaptation',\n",
       "  '(DA)',\n",
       "  'training',\n",
       "  'procedures',\n",
       "  'to',\n",
       "  'ALBERT,',\n",
       "  'such',\n",
       "  'that',\n",
       "  'it',\n",
       "  'can',\n",
       "  'effectively',\n",
       "  'exploit',\n",
       "  'auxiliary',\n",
       "  'data',\n",
       "  'from',\n",
       "  'source',\n",
       "  'domains',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'the',\n",
       "  'OLD',\n",
       "  'performance',\n",
       "  'in',\n",
       "  'a',\n",
       "  'target',\n",
       "  'domain.',\n",
       "  'Experimental',\n",
       "  'results',\n",
       "  'on',\n",
       "  'benchmark',\n",
       "  'datasets',\n",
       "  'show',\n",
       "  'that',\n",
       "  'our',\n",
       "  'approach,',\n",
       "  'ALBERT',\n",
       "  '(DA),',\n",
       "  'obtains',\n",
       "  'the',\n",
       "  'state-of-the-art',\n",
       "  'performance',\n",
       "  'in',\n",
       "  'most',\n",
       "  'cases.',\n",
       "  'Particularly,',\n",
       "  'our',\n",
       "  'approach',\n",
       "  'significantly',\n",
       "  'benefits',\n",
       "  'underrepresented',\n",
       "  'and',\n",
       "  'under-performing',\n",
       "  'classes,',\n",
       "  'with',\n",
       "  'a',\n",
       "  'significant',\n",
       "  'improvement',\n",
       "  'over',\n",
       "  'ALBERT.'],\n",
       " ['Hate',\n",
       "  'speech',\n",
       "  'and',\n",
       "  'profanity',\n",
       "  'detection',\n",
       "  'suffer',\n",
       "  'from',\n",
       "  'data',\n",
       "  'sparsity,',\n",
       "  'especially',\n",
       "  'for',\n",
       "  'languages',\n",
       "  'other',\n",
       "  'than',\n",
       "  'English,',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'subjective',\n",
       "  'nature',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tasks',\n",
       "  'and',\n",
       "  'the',\n",
       "  'resulting',\n",
       "  'annotation',\n",
       "  'incompatibility',\n",
       "  'of',\n",
       "  'existing',\n",
       "  'corpora.',\n",
       "  'In',\n",
       "  'this',\n",
       "  'study,',\n",
       "  'we',\n",
       "  'identify',\n",
       "  'profane',\n",
       "  'subspaces',\n",
       "  'in',\n",
       "  'word',\n",
       "  'and',\n",
       "  'sentence',\n",
       "  'representations',\n",
       "  'and',\n",
       "  'explore',\n",
       "  'their',\n",
       "  'generalization',\n",
       "  'capability',\n",
       "  'on',\n",
       "  'a',\n",
       "  'variety',\n",
       "  'of',\n",
       "  'similar',\n",
       "  'and',\n",
       "  'distant',\n",
       "  'target',\n",
       "  'tasks',\n",
       "  'in',\n",
       "  'a',\n",
       "  'zero-shot',\n",
       "  'setting.',\n",
       "  'This',\n",
       "  'is',\n",
       "  'done',\n",
       "  'monolingually',\n",
       "  '(German)',\n",
       "  'and',\n",
       "  'cross-lingually',\n",
       "  'to',\n",
       "  'closely-related',\n",
       "  '(English),',\n",
       "  'distantly-related',\n",
       "  '(French)',\n",
       "  'and',\n",
       "  'non-related',\n",
       "  '(Arabic)',\n",
       "  'tasks.',\n",
       "  'We',\n",
       "  'observe',\n",
       "  'that,',\n",
       "  'on',\n",
       "  'both',\n",
       "  'similar',\n",
       "  'and',\n",
       "  'distant',\n",
       "  'target',\n",
       "  'tasks',\n",
       "  'and',\n",
       "  'across',\n",
       "  'all',\n",
       "  'languages,',\n",
       "  'the',\n",
       "  'subspace-based',\n",
       "  'representations',\n",
       "  'transfer',\n",
       "  'more',\n",
       "  'effectively',\n",
       "  'than',\n",
       "  'standard',\n",
       "  'BERT',\n",
       "  'representations',\n",
       "  'in',\n",
       "  'the',\n",
       "  'zero-shot',\n",
       "  'setting,',\n",
       "  'with',\n",
       "  'improvements',\n",
       "  'between',\n",
       "  'F1',\n",
       "  '+10.9',\n",
       "  'and',\n",
       "  'F1',\n",
       "  '+42.9',\n",
       "  'over',\n",
       "  'the',\n",
       "  'baselines',\n",
       "  'across',\n",
       "  'all',\n",
       "  'tested',\n",
       "  'monolingual',\n",
       "  'and',\n",
       "  'cross-lingual',\n",
       "  'scenarios.'],\n",
       " ['We',\n",
       "  'introduce',\n",
       "  'HateBERT,',\n",
       "  'a',\n",
       "  're-trained',\n",
       "  'BERT',\n",
       "  'model',\n",
       "  'for',\n",
       "  'abusive',\n",
       "  'language',\n",
       "  'detection',\n",
       "  'in',\n",
       "  'English.',\n",
       "  'The',\n",
       "  'model',\n",
       "  'was',\n",
       "  'trained',\n",
       "  'on',\n",
       "  'RAL-E,',\n",
       "  'a',\n",
       "  'large-scale',\n",
       "  'dataset',\n",
       "  'of',\n",
       "  'Reddit',\n",
       "  'comments',\n",
       "  'in',\n",
       "  'English',\n",
       "  'from',\n",
       "  'communities',\n",
       "  'banned',\n",
       "  'for',\n",
       "  'being',\n",
       "  'offensive,',\n",
       "  'abusive,',\n",
       "  'or',\n",
       "  'hateful',\n",
       "  'that',\n",
       "  'we',\n",
       "  'have',\n",
       "  'curated',\n",
       "  'and',\n",
       "  'made',\n",
       "  'available',\n",
       "  'to',\n",
       "  'the',\n",
       "  'public.',\n",
       "  'We',\n",
       "  'present',\n",
       "  'the',\n",
       "  'results',\n",
       "  'of',\n",
       "  'a',\n",
       "  'detailed',\n",
       "  'comparison',\n",
       "  'between',\n",
       "  'a',\n",
       "  'general',\n",
       "  'pre-trained',\n",
       "  'language',\n",
       "  'model',\n",
       "  'and',\n",
       "  'the',\n",
       "  'retrained',\n",
       "  'version',\n",
       "  'on',\n",
       "  'three',\n",
       "  'English',\n",
       "  'datasets',\n",
       "  'for',\n",
       "  'offensive,',\n",
       "  'abusive',\n",
       "  'language',\n",
       "  'and',\n",
       "  'hate',\n",
       "  'speech',\n",
       "  'detection',\n",
       "  'tasks.',\n",
       "  'In',\n",
       "  'all',\n",
       "  'datasets,',\n",
       "  'HateBERT',\n",
       "  'outperforms',\n",
       "  'the',\n",
       "  'corresponding',\n",
       "  'general',\n",
       "  'BERT',\n",
       "  'model.',\n",
       "  'We',\n",
       "  'also',\n",
       "  'discuss',\n",
       "  'a',\n",
       "  'battery',\n",
       "  'of',\n",
       "  'experiments',\n",
       "  'comparing',\n",
       "  'the',\n",
       "  'portability',\n",
       "  'of',\n",
       "  'the',\n",
       "  'fine-tuned',\n",
       "  'models',\n",
       "  'across',\n",
       "  'the',\n",
       "  'datasets,',\n",
       "  'suggesting',\n",
       "  'that',\n",
       "  'portability',\n",
       "  'is',\n",
       "  'affected',\n",
       "  'by',\n",
       "  'compatibility',\n",
       "  'of',\n",
       "  'the',\n",
       "  'annotated',\n",
       "  'phenomena.'],\n",
       " ['Hateful',\n",
       "  'memes',\n",
       "  'pose',\n",
       "  'a',\n",
       "  'unique',\n",
       "  'challenge',\n",
       "  'for',\n",
       "  'current',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'systems',\n",
       "  'because',\n",
       "  'their',\n",
       "  'message',\n",
       "  'is',\n",
       "  'derived',\n",
       "  'from',\n",
       "  'both',\n",
       "  'text-',\n",
       "  'and',\n",
       "  'visual-modalities.',\n",
       "  'To',\n",
       "  'this',\n",
       "  'effect,',\n",
       "  'Facebook',\n",
       "  'released',\n",
       "  'the',\n",
       "  'Hateful',\n",
       "  'Memes',\n",
       "  'Challenge,',\n",
       "  'a',\n",
       "  'dataset',\n",
       "  'of',\n",
       "  'memes',\n",
       "  'with',\n",
       "  'pre-extracted',\n",
       "  'text',\n",
       "  'captions,',\n",
       "  'but',\n",
       "  'it',\n",
       "  'is',\n",
       "  'unclear',\n",
       "  'whether',\n",
       "  'these',\n",
       "  'synthetic',\n",
       "  'examples',\n",
       "  'generalize',\n",
       "  'to',\n",
       "  '{`}memes',\n",
       "  'in',\n",
       "  'the',\n",
       "  \"wild{'}.\",\n",
       "  'In',\n",
       "  'this',\n",
       "  'paper,',\n",
       "  'we',\n",
       "  'collect',\n",
       "  'hateful',\n",
       "  'and',\n",
       "  'non-hateful',\n",
       "  'memes',\n",
       "  'from',\n",
       "  'Pinterest',\n",
       "  'to',\n",
       "  'evaluate',\n",
       "  'out-of-sample',\n",
       "  'performance',\n",
       "  'on',\n",
       "  'models',\n",
       "  'pre-trained',\n",
       "  'on',\n",
       "  'the',\n",
       "  'Facebook',\n",
       "  'dataset.',\n",
       "  'We',\n",
       "  'find',\n",
       "  'that',\n",
       "  '{`}memes',\n",
       "  'in',\n",
       "  'the',\n",
       "  \"wild{'}\",\n",
       "  'differ',\n",
       "  'in',\n",
       "  'two',\n",
       "  'key',\n",
       "  'aspects:',\n",
       "  '1)',\n",
       "  'Captions',\n",
       "  'must',\n",
       "  'be',\n",
       "  'extracted',\n",
       "  'via',\n",
       "  'OCR,',\n",
       "  'injecting',\n",
       "  'noise',\n",
       "  'and',\n",
       "  'diminishing',\n",
       "  'performance',\n",
       "  'of',\n",
       "  'multimodal',\n",
       "  'models,',\n",
       "  'and',\n",
       "  '2)',\n",
       "  'Memes',\n",
       "  'are',\n",
       "  'more',\n",
       "  'diverse',\n",
       "  'than',\n",
       "  '{`}traditional',\n",
       "  \"memes{'},\",\n",
       "  'including',\n",
       "  'screenshots',\n",
       "  'of',\n",
       "  'conversations',\n",
       "  'or',\n",
       "  'text',\n",
       "  'on',\n",
       "  'a',\n",
       "  'plain',\n",
       "  'background.',\n",
       "  'This',\n",
       "  'paper',\n",
       "  'thus',\n",
       "  'serves',\n",
       "  'as',\n",
       "  'a',\n",
       "  'reality-check',\n",
       "  'for',\n",
       "  'the',\n",
       "  'current',\n",
       "  'benchmark',\n",
       "  'of',\n",
       "  'hateful',\n",
       "  'meme',\n",
       "  'detection',\n",
       "  'and',\n",
       "  'its',\n",
       "  'applicability',\n",
       "  'for',\n",
       "  'detecting',\n",
       "  'real',\n",
       "  'world',\n",
       "  'hate.'],\n",
       " ['Content',\n",
       "  'moderation',\n",
       "  'is',\n",
       "  'often',\n",
       "  'performed',\n",
       "  'by',\n",
       "  'a',\n",
       "  'collaboration',\n",
       "  'between',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'models.',\n",
       "  'However,',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'well',\n",
       "  'understood',\n",
       "  'how',\n",
       "  'to',\n",
       "  'design',\n",
       "  'the',\n",
       "  'collaborative',\n",
       "  'process',\n",
       "  'so',\n",
       "  'as',\n",
       "  'to',\n",
       "  'maximize',\n",
       "  'the',\n",
       "  'combined',\n",
       "  'moderator-model',\n",
       "  'system',\n",
       "  'performance.',\n",
       "  'This',\n",
       "  'work',\n",
       "  'presents',\n",
       "  'a',\n",
       "  'rigorous',\n",
       "  'study',\n",
       "  'of',\n",
       "  'this',\n",
       "  'problem,',\n",
       "  'focusing',\n",
       "  'on',\n",
       "  'an',\n",
       "  'approach',\n",
       "  'that',\n",
       "  'incorporates',\n",
       "  'model',\n",
       "  'uncertainty',\n",
       "  'into',\n",
       "  'the',\n",
       "  'collaborative',\n",
       "  'process.',\n",
       "  'First,',\n",
       "  'we',\n",
       "  'introduce',\n",
       "  'principled',\n",
       "  'metrics',\n",
       "  'to',\n",
       "  'describe',\n",
       "  'the',\n",
       "  'performance',\n",
       "  'of',\n",
       "  'the',\n",
       "  'collaborative',\n",
       "  'system',\n",
       "  'under',\n",
       "  'capacity',\n",
       "  'constraints',\n",
       "  'on',\n",
       "  'the',\n",
       "  'human',\n",
       "  'moderator,',\n",
       "  'quantifying',\n",
       "  'how',\n",
       "  'efficiently',\n",
       "  'the',\n",
       "  'combined',\n",
       "  'system',\n",
       "  'utilizes',\n",
       "  'human',\n",
       "  'decisions.',\n",
       "  'Using',\n",
       "  'these',\n",
       "  'metrics,',\n",
       "  'we',\n",
       "  'conduct',\n",
       "  'a',\n",
       "  'large',\n",
       "  'benchmark',\n",
       "  'study',\n",
       "  'evaluating',\n",
       "  'the',\n",
       "  'performance',\n",
       "  'of',\n",
       "  'state-of-the-art',\n",
       "  'uncertainty',\n",
       "  'models',\n",
       "  'under',\n",
       "  'different',\n",
       "  'collaborative',\n",
       "  'review',\n",
       "  'strategies.',\n",
       "  'We',\n",
       "  'find',\n",
       "  'that',\n",
       "  'an',\n",
       "  'uncertainty-based',\n",
       "  'strategy',\n",
       "  'consistently',\n",
       "  'outperforms',\n",
       "  'the',\n",
       "  'widely',\n",
       "  'used',\n",
       "  'strategy',\n",
       "  'based',\n",
       "  'on',\n",
       "  'toxicity',\n",
       "  'scores,',\n",
       "  'and',\n",
       "  'moreover',\n",
       "  'that',\n",
       "  'the',\n",
       "  'choice',\n",
       "  'of',\n",
       "  'review',\n",
       "  'strategy',\n",
       "  'drastically',\n",
       "  'changes',\n",
       "  'the',\n",
       "  'overall',\n",
       "  'system',\n",
       "  'performance.',\n",
       "  'Our',\n",
       "  'results',\n",
       "  'demonstrate',\n",
       "  'the',\n",
       "  'importance',\n",
       "  'of',\n",
       "  'rigorous',\n",
       "  'metrics',\n",
       "  'for',\n",
       "  'understanding',\n",
       "  'and',\n",
       "  'developing',\n",
       "  'effective',\n",
       "  'moderator-model',\n",
       "  'systems',\n",
       "  'for',\n",
       "  'content',\n",
       "  'moderation,',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'the',\n",
       "  'utility',\n",
       "  'of',\n",
       "  'uncertainty',\n",
       "  'estimation',\n",
       "  'in',\n",
       "  'this',\n",
       "  'domain.']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.split() for x in abstracts[0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ji8yvgUoq9sS",
    "outputId": "b25b9461-c317-4a15-e17d-f70fbc5f304d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Offensive',\n",
       "  'language',\n",
       "  'detection',\n",
       "  '(OLD)',\n",
       "  'has',\n",
       "  'received',\n",
       "  'increasing',\n",
       "  'attention',\n",
       "  'due',\n",
       "  'to',\n",
       "  'its',\n",
       "  'societal',\n",
       "  'impact.',\n",
       "  'Recent',\n",
       "  'work',\n",
       "  'shows',\n",
       "  'that',\n",
       "  'bidirectional',\n",
       "  'transformer',\n",
       "  'based',\n",
       "  'methods',\n",
       "  'obtain',\n",
       "  'impressive',\n",
       "  'performance',\n",
       "  'on',\n",
       "  'OLD.',\n",
       "  'However,',\n",
       "  'such',\n",
       "  'methods',\n",
       "  'usually',\n",
       "  'rely',\n",
       "  'on',\n",
       "  'large-scale',\n",
       "  'well-labeled',\n",
       "  'OLD',\n",
       "  'datasets',\n",
       "  'for',\n",
       "  'model',\n",
       "  'training.',\n",
       "  'To',\n",
       "  'address',\n",
       "  'the',\n",
       "  'issue',\n",
       "  'of',\n",
       "  'data/label',\n",
       "  'scarcity',\n",
       "  'in',\n",
       "  'OLD,',\n",
       "  'in',\n",
       "  'this',\n",
       "  'paper,',\n",
       "  'we',\n",
       "  'propose',\n",
       "  'a',\n",
       "  'simple',\n",
       "  'yet',\n",
       "  'effective',\n",
       "  'domain',\n",
       "  'adaptation',\n",
       "  'approach',\n",
       "  'to',\n",
       "  'train',\n",
       "  'bidirectional',\n",
       "  'transformers.',\n",
       "  'Our',\n",
       "  'approach',\n",
       "  'introduces',\n",
       "  'domain',\n",
       "  'adaptation',\n",
       "  '(DA)',\n",
       "  'training',\n",
       "  'procedures',\n",
       "  'to',\n",
       "  'ALBERT,',\n",
       "  'such',\n",
       "  'that',\n",
       "  'it',\n",
       "  'can',\n",
       "  'effectively',\n",
       "  'exploit',\n",
       "  'auxiliary',\n",
       "  'data',\n",
       "  'from',\n",
       "  'source',\n",
       "  'domains',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'the',\n",
       "  'OLD',\n",
       "  'performance',\n",
       "  'in',\n",
       "  'a',\n",
       "  'target',\n",
       "  'domain.',\n",
       "  'Experimental',\n",
       "  'results',\n",
       "  'on',\n",
       "  'benchmark',\n",
       "  'datasets',\n",
       "  'show',\n",
       "  'that',\n",
       "  'our',\n",
       "  'approach,',\n",
       "  'ALBERT',\n",
       "  '(DA),',\n",
       "  'obtains',\n",
       "  'the',\n",
       "  'state-of-the-art',\n",
       "  'performance',\n",
       "  'in',\n",
       "  'most',\n",
       "  'cases.',\n",
       "  'Particularly,',\n",
       "  'our',\n",
       "  'approach',\n",
       "  'significantly',\n",
       "  'benefits',\n",
       "  'underrepresented',\n",
       "  'and',\n",
       "  'under-performing',\n",
       "  'classes,',\n",
       "  'with',\n",
       "  'a',\n",
       "  'significant',\n",
       "  'improvement',\n",
       "  'over',\n",
       "  'ALBERT.'],\n",
       " ['Hate',\n",
       "  'speech',\n",
       "  'and',\n",
       "  'profanity',\n",
       "  'detection',\n",
       "  'suffer',\n",
       "  'from',\n",
       "  'data',\n",
       "  'sparsity,',\n",
       "  'especially',\n",
       "  'for',\n",
       "  'languages',\n",
       "  'other',\n",
       "  'than',\n",
       "  'English,',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'subjective',\n",
       "  'nature',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tasks',\n",
       "  'and',\n",
       "  'the',\n",
       "  'resulting',\n",
       "  'annotation',\n",
       "  'incompatibility',\n",
       "  'of',\n",
       "  'existing',\n",
       "  'corpora.',\n",
       "  'In',\n",
       "  'this',\n",
       "  'study,',\n",
       "  'we',\n",
       "  'identify',\n",
       "  'profane',\n",
       "  'subspaces',\n",
       "  'in',\n",
       "  'word',\n",
       "  'and',\n",
       "  'sentence',\n",
       "  'representations',\n",
       "  'and',\n",
       "  'explore',\n",
       "  'their',\n",
       "  'generalization',\n",
       "  'capability',\n",
       "  'on',\n",
       "  'a',\n",
       "  'variety',\n",
       "  'of',\n",
       "  'similar',\n",
       "  'and',\n",
       "  'distant',\n",
       "  'target',\n",
       "  'tasks',\n",
       "  'in',\n",
       "  'a',\n",
       "  'zero-shot',\n",
       "  'setting.',\n",
       "  'This',\n",
       "  'is',\n",
       "  'done',\n",
       "  'monolingually',\n",
       "  '(German)',\n",
       "  'and',\n",
       "  'cross-lingually',\n",
       "  'to',\n",
       "  'closely-related',\n",
       "  '(English),',\n",
       "  'distantly-related',\n",
       "  '(French)',\n",
       "  'and',\n",
       "  'non-related',\n",
       "  '(Arabic)',\n",
       "  'tasks.',\n",
       "  'We',\n",
       "  'observe',\n",
       "  'that,',\n",
       "  'on',\n",
       "  'both',\n",
       "  'similar',\n",
       "  'and',\n",
       "  'distant',\n",
       "  'target',\n",
       "  'tasks',\n",
       "  'and',\n",
       "  'across',\n",
       "  'all',\n",
       "  'languages,',\n",
       "  'the',\n",
       "  'subspace-based',\n",
       "  'representations',\n",
       "  'transfer',\n",
       "  'more',\n",
       "  'effectively',\n",
       "  'than',\n",
       "  'standard',\n",
       "  'BERT',\n",
       "  'representations',\n",
       "  'in',\n",
       "  'the',\n",
       "  'zero-shot',\n",
       "  'setting,',\n",
       "  'with',\n",
       "  'improvements',\n",
       "  'between',\n",
       "  'F1',\n",
       "  '+10.9',\n",
       "  'and',\n",
       "  'F1',\n",
       "  '+42.9',\n",
       "  'over',\n",
       "  'the',\n",
       "  'baselines',\n",
       "  'across',\n",
       "  'all',\n",
       "  'tested',\n",
       "  'monolingual',\n",
       "  'and',\n",
       "  'cross-lingual',\n",
       "  'scenarios.'],\n",
       " ['We',\n",
       "  'introduce',\n",
       "  'HateBERT,',\n",
       "  'a',\n",
       "  're-trained',\n",
       "  'BERT',\n",
       "  'model',\n",
       "  'for',\n",
       "  'abusive',\n",
       "  'language',\n",
       "  'detection',\n",
       "  'in',\n",
       "  'English.',\n",
       "  'The',\n",
       "  'model',\n",
       "  'was',\n",
       "  'trained',\n",
       "  'on',\n",
       "  'RAL-E,',\n",
       "  'a',\n",
       "  'large-scale',\n",
       "  'dataset',\n",
       "  'of',\n",
       "  'Reddit',\n",
       "  'comments',\n",
       "  'in',\n",
       "  'English',\n",
       "  'from',\n",
       "  'communities',\n",
       "  'banned',\n",
       "  'for',\n",
       "  'being',\n",
       "  'offensive,',\n",
       "  'abusive,',\n",
       "  'or',\n",
       "  'hateful',\n",
       "  'that',\n",
       "  'we',\n",
       "  'have',\n",
       "  'curated',\n",
       "  'and',\n",
       "  'made',\n",
       "  'available',\n",
       "  'to',\n",
       "  'the',\n",
       "  'public.',\n",
       "  'We',\n",
       "  'present',\n",
       "  'the',\n",
       "  'results',\n",
       "  'of',\n",
       "  'a',\n",
       "  'detailed',\n",
       "  'comparison',\n",
       "  'between',\n",
       "  'a',\n",
       "  'general',\n",
       "  'pre-trained',\n",
       "  'language',\n",
       "  'model',\n",
       "  'and',\n",
       "  'the',\n",
       "  'retrained',\n",
       "  'version',\n",
       "  'on',\n",
       "  'three',\n",
       "  'English',\n",
       "  'datasets',\n",
       "  'for',\n",
       "  'offensive,',\n",
       "  'abusive',\n",
       "  'language',\n",
       "  'and',\n",
       "  'hate',\n",
       "  'speech',\n",
       "  'detection',\n",
       "  'tasks.',\n",
       "  'In',\n",
       "  'all',\n",
       "  'datasets,',\n",
       "  'HateBERT',\n",
       "  'outperforms',\n",
       "  'the',\n",
       "  'corresponding',\n",
       "  'general',\n",
       "  'BERT',\n",
       "  'model.',\n",
       "  'We',\n",
       "  'also',\n",
       "  'discuss',\n",
       "  'a',\n",
       "  'battery',\n",
       "  'of',\n",
       "  'experiments',\n",
       "  'comparing',\n",
       "  'the',\n",
       "  'portability',\n",
       "  'of',\n",
       "  'the',\n",
       "  'fine-tuned',\n",
       "  'models',\n",
       "  'across',\n",
       "  'the',\n",
       "  'datasets,',\n",
       "  'suggesting',\n",
       "  'that',\n",
       "  'portability',\n",
       "  'is',\n",
       "  'affected',\n",
       "  'by',\n",
       "  'compatibility',\n",
       "  'of',\n",
       "  'the',\n",
       "  'annotated',\n",
       "  'phenomena.'],\n",
       " ['Hateful',\n",
       "  'memes',\n",
       "  'pose',\n",
       "  'a',\n",
       "  'unique',\n",
       "  'challenge',\n",
       "  'for',\n",
       "  'current',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'systems',\n",
       "  'because',\n",
       "  'their',\n",
       "  'message',\n",
       "  'is',\n",
       "  'derived',\n",
       "  'from',\n",
       "  'both',\n",
       "  'text-',\n",
       "  'and',\n",
       "  'visual-modalities.',\n",
       "  'To',\n",
       "  'this',\n",
       "  'effect,',\n",
       "  'Facebook',\n",
       "  'released',\n",
       "  'the',\n",
       "  'Hateful',\n",
       "  'Memes',\n",
       "  'Challenge,',\n",
       "  'a',\n",
       "  'dataset',\n",
       "  'of',\n",
       "  'memes',\n",
       "  'with',\n",
       "  'pre-extracted',\n",
       "  'text',\n",
       "  'captions,',\n",
       "  'but',\n",
       "  'it',\n",
       "  'is',\n",
       "  'unclear',\n",
       "  'whether',\n",
       "  'these',\n",
       "  'synthetic',\n",
       "  'examples',\n",
       "  'generalize',\n",
       "  'to',\n",
       "  '{`}memes',\n",
       "  'in',\n",
       "  'the',\n",
       "  \"wild{'}.\",\n",
       "  'In',\n",
       "  'this',\n",
       "  'paper,',\n",
       "  'we',\n",
       "  'collect',\n",
       "  'hateful',\n",
       "  'and',\n",
       "  'non-hateful',\n",
       "  'memes',\n",
       "  'from',\n",
       "  'Pinterest',\n",
       "  'to',\n",
       "  'evaluate',\n",
       "  'out-of-sample',\n",
       "  'performance',\n",
       "  'on',\n",
       "  'models',\n",
       "  'pre-trained',\n",
       "  'on',\n",
       "  'the',\n",
       "  'Facebook',\n",
       "  'dataset.',\n",
       "  'We',\n",
       "  'find',\n",
       "  'that',\n",
       "  '{`}memes',\n",
       "  'in',\n",
       "  'the',\n",
       "  \"wild{'}\",\n",
       "  'differ',\n",
       "  'in',\n",
       "  'two',\n",
       "  'key',\n",
       "  'aspects:',\n",
       "  '1)',\n",
       "  'Captions',\n",
       "  'must',\n",
       "  'be',\n",
       "  'extracted',\n",
       "  'via',\n",
       "  'OCR,',\n",
       "  'injecting',\n",
       "  'noise',\n",
       "  'and',\n",
       "  'diminishing',\n",
       "  'performance',\n",
       "  'of',\n",
       "  'multimodal',\n",
       "  'models,',\n",
       "  'and',\n",
       "  '2)',\n",
       "  'Memes',\n",
       "  'are',\n",
       "  'more',\n",
       "  'diverse',\n",
       "  'than',\n",
       "  '{`}traditional',\n",
       "  \"memes{'},\",\n",
       "  'including',\n",
       "  'screenshots',\n",
       "  'of',\n",
       "  'conversations',\n",
       "  'or',\n",
       "  'text',\n",
       "  'on',\n",
       "  'a',\n",
       "  'plain',\n",
       "  'background.',\n",
       "  'This',\n",
       "  'paper',\n",
       "  'thus',\n",
       "  'serves',\n",
       "  'as',\n",
       "  'a',\n",
       "  'reality-check',\n",
       "  'for',\n",
       "  'the',\n",
       "  'current',\n",
       "  'benchmark',\n",
       "  'of',\n",
       "  'hateful',\n",
       "  'meme',\n",
       "  'detection',\n",
       "  'and',\n",
       "  'its',\n",
       "  'applicability',\n",
       "  'for',\n",
       "  'detecting',\n",
       "  'real',\n",
       "  'world',\n",
       "  'hate.'],\n",
       " ['Content',\n",
       "  'moderation',\n",
       "  'is',\n",
       "  'often',\n",
       "  'performed',\n",
       "  'by',\n",
       "  'a',\n",
       "  'collaboration',\n",
       "  'between',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'models.',\n",
       "  'However,',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'well',\n",
       "  'understood',\n",
       "  'how',\n",
       "  'to',\n",
       "  'design',\n",
       "  'the',\n",
       "  'collaborative',\n",
       "  'process',\n",
       "  'so',\n",
       "  'as',\n",
       "  'to',\n",
       "  'maximize',\n",
       "  'the',\n",
       "  'combined',\n",
       "  'moderator-model',\n",
       "  'system',\n",
       "  'performance.',\n",
       "  'This',\n",
       "  'work',\n",
       "  'presents',\n",
       "  'a',\n",
       "  'rigorous',\n",
       "  'study',\n",
       "  'of',\n",
       "  'this',\n",
       "  'problem,',\n",
       "  'focusing',\n",
       "  'on',\n",
       "  'an',\n",
       "  'approach',\n",
       "  'that',\n",
       "  'incorporates',\n",
       "  'model',\n",
       "  'uncertainty',\n",
       "  'into',\n",
       "  'the',\n",
       "  'collaborative',\n",
       "  'process.',\n",
       "  'First,',\n",
       "  'we',\n",
       "  'introduce',\n",
       "  'principled',\n",
       "  'metrics',\n",
       "  'to',\n",
       "  'describe',\n",
       "  'the',\n",
       "  'performance',\n",
       "  'of',\n",
       "  'the',\n",
       "  'collaborative',\n",
       "  'system',\n",
       "  'under',\n",
       "  'capacity',\n",
       "  'constraints',\n",
       "  'on',\n",
       "  'the',\n",
       "  'human',\n",
       "  'moderator,',\n",
       "  'quantifying',\n",
       "  'how',\n",
       "  'efficiently',\n",
       "  'the',\n",
       "  'combined',\n",
       "  'system',\n",
       "  'utilizes',\n",
       "  'human',\n",
       "  'decisions.',\n",
       "  'Using',\n",
       "  'these',\n",
       "  'metrics,',\n",
       "  'we',\n",
       "  'conduct',\n",
       "  'a',\n",
       "  'large',\n",
       "  'benchmark',\n",
       "  'study',\n",
       "  'evaluating',\n",
       "  'the',\n",
       "  'performance',\n",
       "  'of',\n",
       "  'state-of-the-art',\n",
       "  'uncertainty',\n",
       "  'models',\n",
       "  'under',\n",
       "  'different',\n",
       "  'collaborative',\n",
       "  'review',\n",
       "  'strategies.',\n",
       "  'We',\n",
       "  'find',\n",
       "  'that',\n",
       "  'an',\n",
       "  'uncertainty-based',\n",
       "  'strategy',\n",
       "  'consistently',\n",
       "  'outperforms',\n",
       "  'the',\n",
       "  'widely',\n",
       "  'used',\n",
       "  'strategy',\n",
       "  'based',\n",
       "  'on',\n",
       "  'toxicity',\n",
       "  'scores,',\n",
       "  'and',\n",
       "  'moreover',\n",
       "  'that',\n",
       "  'the',\n",
       "  'choice',\n",
       "  'of',\n",
       "  'review',\n",
       "  'strategy',\n",
       "  'drastically',\n",
       "  'changes',\n",
       "  'the',\n",
       "  'overall',\n",
       "  'system',\n",
       "  'performance.',\n",
       "  'Our',\n",
       "  'results',\n",
       "  'demonstrate',\n",
       "  'the',\n",
       "  'importance',\n",
       "  'of',\n",
       "  'rigorous',\n",
       "  'metrics',\n",
       "  'for',\n",
       "  'understanding',\n",
       "  'and',\n",
       "  'developing',\n",
       "  'effective',\n",
       "  'moderator-model',\n",
       "  'systems',\n",
       "  'for',\n",
       "  'content',\n",
       "  'moderation,',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'the',\n",
       "  'utility',\n",
       "  'of',\n",
       "  'uncertainty',\n",
       "  'estimation',\n",
       "  'in',\n",
       "  'this',\n",
       "  'domain.']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = []\n",
    "for x in abstracts[0:5]:\n",
    "  my_list.append(x.split())\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2gF3meKrJ6p"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intro_to_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
