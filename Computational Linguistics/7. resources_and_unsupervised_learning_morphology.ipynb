{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3b9L9wys0kT"
   },
   "source": [
    "# Resources for Morphology\n",
    "\n",
    "### CELEX\n",
    "This database comes from the **Ce**nter for **Lex**ical Information, developed at the Max Planck Institute for Psycholinguistics (Netherlands). It attempts to provide a mapping between words in three Germanic languages: English, Dutch, and German. It provides information for the orthography, phonology, morphology, syntax, and frequency of either (1) different lemmas or root forms or (2) raw word forms. It is *not* open source and you need a license to use this dataset, so we will not use this. However, you may see it referenced if you read further into papers on English morphology, especially older ones. \n",
    "\n",
    "### English Lexicon Project (ELP)\n",
    "\n",
    "In psycholinguistics, researchers have studied how morphologically complex words are processed in the brain. Because of this, they have created rich datasets that annotate for morphological information that psycholinguists might be interested in. The English Lexicon Project ([https://elexicon.wustl.edu/](https://elexicon.wustl.edu/)) is one such resource. It has a complex data schema that allows researchers to look for words with certain properties. Remember that English morphology can generally be broken down into the following categories:\n",
    "\n",
    "* Derivational morphology (changes word categories; surprise --> surprisal)\n",
    "* Inflectional morphology (retains word categories; cat --> cats)\n",
    "* Prefixes (before the root)\n",
    "* Suffixes (after the root)\n",
    "\n",
    "That data schema looks like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "D9tLHvWWcKKn",
    "outputId": "1d31be75-867e-4acb-bfd7-d46ad1b80d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: citylex in /usr/local/lib/python3.7/dist-packages (0.1.9)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from citylex) (3.17.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from citylex) (1.1.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from citylex) (2.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->citylex) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->citylex) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->citylex) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->citylex) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->citylex) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->citylex) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->citylex) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->citylex) (3.0.4)\n",
      "INFO: Requesting URL: https://raw.githubusercontent.com/kylebgorman/ELP-annotations/master/ELP.csv\n",
      "INFO: Collected 68,623 ELP analyses\n",
      "INFO: Writing out textproto...\n",
      "INFO: Writing out TSV...\n",
      "INFO: Success!\n",
      "citylex.textproto  citylex.tsv\tsample_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordform</th>\n",
       "      <th>elp_morph_sp</th>\n",
       "      <th>elp_nmorph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79667</th>\n",
       "      <td>zur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79668</th>\n",
       "      <td>zurcher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79669</th>\n",
       "      <td>zurich</td>\n",
       "      <td>{zurich}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79670</th>\n",
       "      <td>zwei</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79671</th>\n",
       "      <td>zworykin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wordform elp_morph_sp  elp_nmorph\n",
       "79667       zur          NaN         NaN\n",
       "79668   zurcher          NaN         NaN\n",
       "79669    zurich     {zurich}         1.0\n",
       "79670      zwei          NaN         NaN\n",
       "79671  zworykin          NaN         NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading some of the resources from open source\n",
    "\n",
    "!pip install citylex # morphology dataset interface\n",
    "!citylex --elp # download the english lexicon project\n",
    "!ls # show its location in drive\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "citylex = pd.read_csv(\"./citylex.tsv\", sep=\"\\t\")\n",
    "citylex.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-bAEkiK7bBE"
   },
   "source": [
    "### Many languages with a \"universal\" grammatical schema: Unimorph\n",
    "\n",
    "Attempts to unify some of the challenges of using morphological resources like CELEX and the ELP above by _specifically labeling_ grammatical properties of the morphemes. \n",
    "\n",
    "Unimorph (Nicolai et al., 2020) has a huge repository of languages available with morphological annotations: https://github.com/orgs/unimorph/repositories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "Iwv9AWmX8n1Z",
    "outputId": "b9454142-d1dd-4a49-85bb-dfa9fcbed0b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Requesting URL: https://raw.githubusercontent.com/kylebgorman/ELP-annotations/master/ELP.csv\n",
      "INFO: Collected 68,623 ELP analyses\n",
      "INFO: Requesting URL: https://raw.githubusercontent.com/unimorph/eng/master/eng\n",
      "INFO: Collected 115,523 UniMorph analyses\n",
      "INFO: Writing out textproto...\n",
      "INFO: Writing out TSV...\n",
      "INFO: Success!\n",
      "citylex.textproto  citylex.tsv\tsample_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordform</th>\n",
       "      <th>elp_morph_sp</th>\n",
       "      <th>elp_nmorph</th>\n",
       "      <th>unimorph_morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142852</th>\n",
       "      <td>œconomizing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>œconomize_V;V.PTCP;PRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142853</th>\n",
       "      <td>œstruate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>œstruate_V;NFIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142854</th>\n",
       "      <td>œstruated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>œstruate_V;PST^œstruate_V;V.PTCP;PST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142855</th>\n",
       "      <td>œstruates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>œstruate_V;3;SG;PRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142856</th>\n",
       "      <td>œstruating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>œstruate_V;V.PTCP;PRS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           wordform  ...                        unimorph_morph\n",
       "142852  œconomizing  ...                œconomize_V;V.PTCP;PRS\n",
       "142853     œstruate  ...                       œstruate_V;NFIN\n",
       "142854    œstruated  ...  œstruate_V;PST^œstruate_V;V.PTCP;PST\n",
       "142855    œstruates  ...                   œstruate_V;3;SG;PRS\n",
       "142856   œstruating  ...                 œstruate_V;V.PTCP;PRS\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!citylex --unimorph --elp\n",
    "!ls\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "citylex = pd.read_csv(\"./citylex.tsv\", sep=\"\\t\")\n",
    "citylex.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Gwd1PVvAsVk"
   },
   "source": [
    "### The Unimorph Schema\n",
    "\n",
    "Let's break down some of the data in the `unimorph_morph` column above.\n",
    "\n",
    "> \"Œconomize\": Obsolete spelling of economize.\n",
    "\n",
    "Unimorph uses some specific notation to express complex linguistic concepts. For example, the term \"œconomizing\" comes from the verb \"œconomize\". Unimorph therefore marks \"œconomize\" as a verb with a special underscore (`_V`) broken into (separated by `;`) that correspond to other grammatical properties of the word.\n",
    "\n",
    "* `V.PTCP` is \"Verb: Participle\"\n",
    "  *  Because \"œconomizing\" ends in `-ing`, in English this makes it a \"participle\", which is just another way of saying a verb that also acts like an adverb (e.g., words that end in -ly in English)\n",
    "  * For the curious: Other participles in English include \"-ed\" forms of verbs, such as, \"I have brush**ed** my teeth\"). This is different from the regular -ed (e.g., \"I brush**ed** my teeth\" would get a different tag in Unimorph)\n",
    "* `PRS` is \"Present\"\n",
    "  * \"Present\" in English is a way of encoding grammatical **tense**; i.e., of expressing at what time an event takes place. When something takes place in the present tense, it often means the event is currently taking place (compare \"I eat sandwiches for lunch\" and \"I ate sandwiches for lunch\").\n",
    "\n",
    "Many of the tags are linguistically informed and try to capture a broad range of linguistic **form-to-meaning mappings**.\n",
    "\n",
    "If we know something about the grammatical purpose of a sequence of  (e.g., `PRS` can map onto \"-s\" in English), we might then ask an NLP system (e.g., a finite state automaton/finite state transducer) to produce a new form of a verb that it has never seen before given a base form of a verb (\"hiss\") and the `PRS` feature.\n",
    "\n",
    "Recall our Turkish example from Monday?\n",
    "\n",
    "* `-dE` can be realized in two forms: `-de` and `-da` depending on the sounds in the prior morphemes.\n",
    "* Unimorph should treat both of these the same using some kind of consistent \"tag\" or label that defines what the meaning of \"-dE\" is.\n",
    "\n",
    "And for ambiguous morphemes, like -s in English, there are two relations:\n",
    "* -s for verbs\n",
    "* -s for nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "CJVLoOR5QKtM",
    "outputId": "829c96cd-cd15-4a22-9c3a-58f6d5a8b7ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordform</th>\n",
       "      <th>elp_morph_sp</th>\n",
       "      <th>elp_nmorph</th>\n",
       "      <th>unimorph_morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14800</th>\n",
       "      <td>bosses</td>\n",
       "      <td>{boss}&gt;s&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>boss_V;3;SG;PRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18874</th>\n",
       "      <td>cats</td>\n",
       "      <td>{cat}&gt;s&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>cat_V;3;SG;PRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29191</th>\n",
       "      <td>dances</td>\n",
       "      <td>{dance}&gt;s&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>dance_V;3;SG;PRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60063</th>\n",
       "      <td>hour</td>\n",
       "      <td>{hour}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60070</th>\n",
       "      <td>hours</td>\n",
       "      <td>{hour}&gt;s&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75895</th>\n",
       "      <td>mice</td>\n",
       "      <td>{mice}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127455</th>\n",
       "      <td>time</td>\n",
       "      <td>{time}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>time_V;NFIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wordform elp_morph_sp  elp_nmorph    unimorph_morph\n",
       "14800    bosses    {boss}>s>         2.0   boss_V;3;SG;PRS\n",
       "18874      cats     {cat}>s>         2.0    cat_V;3;SG;PRS\n",
       "29191    dances   {dance}>s>         2.0  dance_V;3;SG;PRS\n",
       "60063      hour       {hour}         1.0               NaN\n",
       "60070     hours    {hour}>s>         2.0               NaN\n",
       "75895      mice       {mice}         1.0               NaN\n",
       "127455     time       {time}         1.0       time_V;NFIN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Different morphological representations \n",
    "\n",
    "citylex[citylex['wordform'].isin({\"dances\", \"cats\", \"mice\", \"bosses\", \"hours\", \"hour\", \"time\"})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2soAFHVTQx78"
   },
   "source": [
    "As we can see, Unimorph is not complete. For example, many common words like \"mice\" do not have an annotation, and it thinks many plural nouns are verbs. Even more problematically, much of the data was generated by rules, which leads to errors that are probably overly general (such as \"cats\" being a verb. Without better rules, Unimorph will continue to be insufficient for many applications. For this reason, the Unimorph resource is mostly used to generate possible valid pairs from known form-to-meaning mappings. Even then, the **limits of the size of the data** will pose a problem for any useful analysis of real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtNeFQhERcGd"
   },
   "source": [
    "So, in summary: Many resources are incomplete for different reasons. The English Lexicon project has decent segmentations for morphemes within English words, and Unimorph has clear tags associated with the role those morphemes play in the word without information as to where they occur. In principle, both resources could complement each other.\n",
    "\n",
    "In general, making \"complete\" morphological resources that are flexible and error-free is really hard. Encoding both information about **form** and **function** is also a major challenge. This is why a lot of approaches to morphology have moved to **unsupervised methods** that focus primarily on form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ujh5KGys3l-"
   },
   "source": [
    "# Supervised vs. Unsupervised Learning\n",
    "\n",
    "Supervised learning is when you use data that has already been labeled or measured. For example, if we have a dataset of documents, and we want to predict whether they are spam or not, we might have a pre-existing dataset of emails that have been labeled as either being spam or not ($S$). We can then try to predict the _label_ associated with each email from the words ($W$) in our vocabulary ($V$) it contains. This model is a **supervised model** because we *know* the labels ahead of time. \n",
    "\n",
    "For example, if we see that ALL (100%) of the emails that are labeled \"spam\" have the word \"money\" in them, and NONE (0%) of the emails that are not spam have that word, then we might want to say that:\n",
    "\n",
    "```python\n",
    "my_tokenized_email = [\"Please\", \"send\", \"us\", \"all\", \"your\", \"money\", \"!\", \"!\"]\n",
    "if(\"money\" in my_tokenized_email):\n",
    "  email_is_spam = True\n",
    "else:\n",
    "  email_is_spam = False\n",
    "```\n",
    "\n",
    "When building natural language processing applications, we often do not want to use very strict, hard-coded rules because we would probably miss out on real emails. A supervised learning model will learn sophisticated **weights** on all of the words ($w$) in our vocabulary ($V$), but it is very similar in kind to the rule above. Importantly, we made our decision on the basis of _labels_ here. \n",
    "\n",
    "In the case of spam detection, it makes sense to require labels. But, not all cases are well-suited to labelled data. In particular, researchers often want to gain as much out of datasets that have need for **linguistic expertise** as possible, without hiring linguists or getting data annotations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKNWZYciXdTF"
   },
   "source": [
    "## Processing sequences to predict morphology\n",
    "\n",
    "One way to think about how we can identify the **morphological structure** of a word is to think of it as a sequence labeling problem. For example, we might want to take a word like \"dances\" and produce a series of labels like \"dance_V;3;SG;PRS\". In this case, we could frame the problem as something like learning the mapping between word forms and morpheme categories, or the syntactic or semantic information they carry.\n",
    "\n",
    "Wordform | Morpheme category\n",
    "--- | ---\n",
    "d | ROOT\n",
    "a | ROOT\n",
    "n | ROOT\n",
    "c | ROOT\n",
    "e | ROOT\n",
    "s | 3;SG;PRS\n",
    "\n",
    "Where we **predict** that the -s ending is \"third person singular in the present tense.\" We could also predict something simpler -- such as whether it is third person or not, or whether it is singular or not, or whether it is the present tense or not. In English, this is easy because the -s mostly means all of these things at the same time.\n",
    "\n",
    "But, for many languages this is not so easy. In some languages, such as Finnish, we simply cannot observe all possible forms of a word (up to thousands of variants in some cases) and many morphemes are concatenated together, each with distinct meanings. This is analogous to the idea of not being able to process all sentences -- there will always be unseen data. So, another reason we consider unsupervised learning approaches is the need for tools to **combat sparsity** in our data. \n",
    "\n",
    "## Unsupervised learning to reduce data sparsity\n",
    "\n",
    "We can consider how we can learn the best morphological \"vocabulary\" from data. For this, we can devise simple **unsupervised learning** algorithms to characterize regularities in our data that we can take advantage of. Without labels, we will try to find as many morphemes as possible so we can segment words into their component parts. (Figuring out what to call these morphemes, or identify what grammatical role they play, is a much harder question).\n",
    "\n",
    "## Algorithms for morphology\n",
    "\n",
    "There are many unsupervised learning algorithms for morphology. Nearly all of them make use of probability theory, such as **transition probabilities** and mutual information like we have computed before. One baseline algorithm for learning morphology-like sequences is the Morfessor algorithm, which we discuss below. We will also cover this in more detail on Friday, alongside the Byte-Pair Encoding (BPE) framework. Both of these are **bottom-up**, data-driven approaches to learning informative substrings that characterize word forms.\n",
    "\n",
    "Note: There are elements of the Morfessor algorithm that are challenging until we get to later in the class. If you read the paper, be aware that some of the algorithms will be covered in class (EM or Expectation Maximization), and others will not (Viterbi).\n",
    "\n",
    "## Morfessor algorithm (Creutz & Lagus, 2002) -- Assigned reading\n",
    "\n",
    "Two major components:\n",
    "* Lexicon (words or word-like units -- \"constructions\" -- and their properties)\n",
    "* Grammar (a system that controls how these units combine into \"compounds\")\n",
    "\n",
    "Two general assumptions:\n",
    "* \"Compounds\" are formed by one or more \"constructions\"\n",
    "  * Maximally, a word can have as many constructions as \"atoms\" (e.g., characters or letters)\n",
    "  * Corollary: We cannot have \"invisible\" constructions (e.g., **zero derivation**)\n",
    "* Each construction within a compound can occur **independently** -- words are effectively constructed at random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQKhO9wFlad-"
   },
   "source": [
    "# Friday\n",
    "\n",
    "1. We will discuss how Morfessor decides how to segment words into their component morphs. How does Morfessor iteratively learn -- without labels -- what morphs should be in its codebook?\n",
    "\n",
    "2. We will discuss how Byte Pair Encoding (BPE) works.\n",
    "\n",
    "3. We will compare BPE segmentations with morphologically \"gold\" segmentations to see how much they align with each other.\n",
    "\n",
    "## HW2 is due Friday by midnight (11:59pm Eastern).\n",
    "  ### Remember to upload it as a .ipynb file\n",
    "  ### Please reach out if you have any questions!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "resources_and_unsupervised_learning_morphology.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
